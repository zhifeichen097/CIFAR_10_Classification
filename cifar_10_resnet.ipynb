{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar-10_resnet.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1TiSefGh2xVWY_KvrkHFFTmBA0u8mDWMp",
      "authorship_tag": "ABX9TyMSWUjKrdGTH9lTYjrXiR2W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhifeichen097/CIFAR_10_Classification/blob/main/cifar_10_resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuRUZ9CWnsB3"
      },
      "source": [
        "## Dependency"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5ufikM9mBHu"
      },
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torch.nn as nn"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlHGgUZ8noEt"
      },
      "source": [
        "## Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCHishSJQjVN"
      },
      "source": [
        "def unpickle_all_data(directory):\n",
        "    \n",
        "    # Initialize the variables\n",
        "    train = dict()\n",
        "    test = dict()\n",
        "    train_x = []\n",
        "    train_y = []\n",
        "    test_x = []\n",
        "    test_y = []\n",
        "    \n",
        "    # Iterate through all files that we want, train and test\n",
        "    # Train is separated into batches\n",
        "    for filename in listdir(directory): \n",
        "            # The train data\n",
        "            if 'data_batch' in filename:\n",
        "                print('Processing file: %s' % filename)\n",
        "                \n",
        "                # Opent the file\n",
        "                with open(directory + '/' + filename, 'rb') as fo:\n",
        "                    data = pickle.load(fo, encoding='bytes')\n",
        "\n",
        "                if 'data' not in train: \n",
        "                    train['data'] = data[b'data']\n",
        "                    train['labels'] = np.array(data[b'labels'])\n",
        "                else:\n",
        "                    train['data'] = np.concatenate((train['data'], data[b'data']))\n",
        "                    train['labels'] = np.concatenate((train['labels'], data[b'labels']))\n",
        "            # The test data\n",
        "            elif 'test_batch' in filename:\n",
        "                print('Handing file: %s' % filename)\n",
        "                \n",
        "                # Open the file\n",
        "                with open(directory + '/' + filename, 'rb') as fo:\n",
        "                    data = pickle.load(fo, encoding='bytes')\n",
        "                \n",
        "                test['data'] = data[b'data']\n",
        "                test['labels'] = data[b'labels']\n",
        "    \n",
        "    # Manipulate the data to the propper format\n",
        "    for image in train['data']:\n",
        "        train_x.append(np.transpose(np.reshape(image,(3, 32,32)), (1,2,0)))\n",
        "    train_y = [label for label in train['labels']]\n",
        "    \n",
        "    for image in test['data']:\n",
        "        test_x.append(np.transpose(np.reshape(image,(3, 32,32)), (1,2,0)))\n",
        "    test_y = [label for label in test['labels']]\n",
        "    \n",
        "    # Transform the data to np array format\n",
        "    train_x = np.array(train_x)\n",
        "    train_y = np.array(train_y)\n",
        "    test_x = np.array(test_x)\n",
        "    test_y = np.array(test_y)\n",
        "    \n",
        "    return (train_x, train_y), (test_x, test_y)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-V9M-HhXO2D",
        "outputId": "0f30a6ef-9dca-43a0-9e9a-09647edfaa86"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = unpickle_all_data('/content/drive/MyDrive/Colab Notebooks/resnet/data')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file: data_batch_1\n",
            "Processing file: data_batch_2\n",
            "Processing file: data_batch_3\n",
            "Processing file: data_batch_4\n",
            "Processing file: data_batch_5\n",
            "Handing file: test_batch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsZqeqHOmMiK"
      },
      "source": [
        "class CIFAR10_Loader(Dataset):\n",
        "      def __init__(self, data, label, transform=None):\n",
        "        self.data = data\n",
        "        self.label = label\n",
        "        self.transform = transform\n",
        "        self.img_shape = data.shape\n",
        "\n",
        "      def __getitem__(self, index):\n",
        "        img = Image.fromarray(self.data[index])\n",
        "        label = self.label[index]\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        else:\n",
        "            img_to_tensor = transforms.ToTensor()\n",
        "            img = img_to_tensor(img)\n",
        "        return img, label\n",
        "      \n",
        "      def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "def normalize_data(data):\n",
        "  mean = data.mean(axis = (0, 1, 2)) / 255.0\n",
        "  std = data.std(axis = (0, 1, 2)) / 255.0\n",
        "  normalize = transforms.Normalize(mean, std)\n",
        "  return normalize\n",
        "\n",
        "### data augmentation ###\n",
        "train_transform_aug = transforms.Compose([\n",
        "    transforms.Resize((40, 40)),      \n",
        "    transforms.RandomCrop((32, 32)),   \n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ToTensor(),\n",
        "    normalize_data(x_train)\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    normalize_data(x_train)\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    normalize_data(x_test)\n",
        "])\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Swu8hkYfmeQW"
      },
      "source": [
        "# split the validation set out\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train_split, x_val_split, y_train_split, y_val_split = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "train_set = CIFAR10_Loader(data=x_train_split, label=y_train_split, transform=train_transform_aug)\n",
        "val_set = CIFAR10_Loader(data=x_val_split, label=y_val_split, transform=val_transform)\n",
        "test_set = CIFAR10_Loader(data=x_test, label=y_test, transform=test_transform)\n",
        "\n",
        "#print(len(train_set))\n",
        "\n",
        "train_loader = DataLoader(dataset=train_set,batch_size=64, shuffle=True, num_workers=1)\n",
        "val_loader = DataLoader(dataset=val_set,batch_size=64, shuffle=False, num_workers=1)\n",
        "test_loader = DataLoader(dataset=test_set,batch_size=64, shuffle=False, num_workers=1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wXLmYnBrlb7",
        "outputId": "25269ebe-ed5d-4db8-a1f1-cd0fcbbf2a02"
      },
      "source": [
        "## test ##\n",
        "imgs, lbls = iter(train_loader).next()\n",
        "print(imgs.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 3, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKEjYOQQtrOM"
      },
      "source": [
        "## ResNet Architecture\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERi5Nkpes__c"
      },
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "    def __init__(self, in_channels, out_channels, i_downsample=None, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "       \n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, stride=stride, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.i_downsample = i_downsample\n",
        "        self.stride = stride\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "      identity = x.clone()\n",
        "\n",
        "      x = self.relu(self.bn1(self.conv1(x)))\n",
        "      x = self.bn2(self.conv2(x))\n",
        "\n",
        "      if self.i_downsample is not None:\n",
        "          identity = self.i_downsample(identity)\n",
        "\n",
        "      x += identity\n",
        "      x = self.relu(x)\n",
        "      return x\n",
        "\n",
        "class BottleNeck(nn.Module):\n",
        "  expansion = 4\n",
        "\n",
        "  def __init__(self, in_channel, out_channel, i_downsample=None, stride=1):\n",
        "    super(BottleNeck, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(in_channel, out_channel, kernel_size=1, stride=1, padding=0)\n",
        "    self.bn1 = nn.BatchNorm2d(out_channel)\n",
        "        \n",
        "    self.conv2 = nn.Conv2d(out_channel, out_channel, kernel_size=3, stride=stride, padding=1)\n",
        "    self.bn2 = nn.BatchNorm2d(out_channel)\n",
        "        \n",
        "    self.conv3 = nn.Conv2d(out_channel, out_channel*self.expansion, kernel_size=1, stride=1, padding=0)\n",
        "    self.bn3 = nn.BatchNorm2d(out_channel*self.expansion)\n",
        "\n",
        "    self.i_downsample = i_downsample\n",
        "    self.stride = stride\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    identity = x.clone()\n",
        "\n",
        "    x = self.relu(self.bn1(self.conv1(x)))\n",
        "    x = self.relu(self.bn2(self.conv2(x)))\n",
        "    x = self.bn3(self.conv3(x))\n",
        "\n",
        "    if self.i_downsample:\n",
        "      identity = self.i_downsample(identity)\n",
        "    \n",
        "    x += identity\n",
        "    x = self.relu(x)\n",
        "    return x \n",
        "\n",
        "class ResNet(nn.Module):\n",
        "  def __init__(self, basic_block, layer_list, num_classes, num_channels=3):\n",
        "    super(ResNet, self).__init__()\n",
        "\n",
        "    self.in_channels = 64\n",
        "\n",
        "    self.conv1 = nn.Conv2d(num_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(64)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.max_pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "    self.layer1 = self.make_layer(basic_block, layer_list[0], out_channel=64)\n",
        "    self.layer2 = self.make_layer(basic_block, layer_list[1], out_channel=128, stride=2)\n",
        "    self.layer3 = self.make_layer(basic_block, layer_list[2], out_channel=256, stride=2)\n",
        "    self.layer4 = self.make_layer(basic_block, layer_list[3], out_channel=512, stride=2)\n",
        "\n",
        "    self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "    self.fc = nn.Linear(512*basic_block.expansion, num_classes)\n",
        "\n",
        "  def make_layer(self, basic_block, num_layers, out_channel, stride=1):\n",
        "    ii_downsample = None\n",
        "    layers = []\n",
        "        \n",
        "    if stride != 1 or self.in_channels != out_channel*basic_block.expansion:\n",
        "        ii_downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels, out_channel*basic_block.expansion, kernel_size=1, stride=stride),\n",
        "                nn.BatchNorm2d(out_channel*basic_block.expansion)\n",
        "        )\n",
        "    \n",
        "    layers.append(basic_block(self.in_channels, out_channel, i_downsample=ii_downsample, stride=stride))\n",
        "    self.in_channels = out_channel*basic_block.expansion\n",
        "        \n",
        "    for i in range(num_layers-1):\n",
        "      layers.append(basic_block(self.in_channels, out_channel))\n",
        "            \n",
        "    return nn.Sequential(*layers)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.relu(self.bn1(self.conv1(x)))\n",
        "    x = self.max_pool(x)\n",
        "\n",
        "    x = self.layer1(x)\n",
        "    x = self.layer2(x)\n",
        "    x = self.layer3(x)\n",
        "    #print(x.shape)\n",
        "    x = self.layer4(x)\n",
        "        \n",
        "    x = self.avg_pool(x)\n",
        "    x = x.reshape(x.shape[0], -1)\n",
        "    x = self.fc(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UWc-UTgjNaw",
        "outputId": "03f279ec-fb53-4f2b-f5aa-92d06dfa53b4"
      },
      "source": [
        "def ResNet50(num_classes, channels=3):\n",
        "    return ResNet(BottleNeck, [3,4,6,3], num_classes, channels)\n",
        "\n",
        "## test ##\n",
        "net = ResNet50(10)\n",
        "y = net(torch.randn(64, 3, 32, 32))\n",
        "print(y.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEBollJaoEGZ"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXWoPu3poHbQ"
      },
      "source": [
        "import torch.optim as optim\n",
        "net = ResNet50(10).to('cuda')\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=0.0001)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.1, patience=5)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YS6ikcmdowVS",
        "outputId": "1d0b8f0b-4ed9-4110-de76-a496006afe9d"
      },
      "source": [
        "EPOCHS = 200\n",
        "total_train_loss = []\n",
        "total_val_loss = []\n",
        "score_list = []\n",
        "for epoch in range(EPOCHS):\n",
        "    losses = []\n",
        "    running_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i, inp in enumerate(train_loader):\n",
        "        inputs, labels = inp\n",
        "        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
        "        optimizer.zero_grad()\n",
        "    \n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        if i%100 == 0 and i > 0:\n",
        "            print(f'Loss [{epoch+1}, {i}](epoch, minibatch): ', running_loss / 100)\n",
        "            running_loss = 0.0\n",
        "\n",
        "    avg_loss = sum(losses)/len(losses)\n",
        "    total_train_loss.append(avg_loss)\n",
        "    scheduler.step(avg_loss)\n",
        "\n",
        "  #<---------------Validation Loop---------------------->\n",
        "    with torch.no_grad():\n",
        "      for i, inp in enumerate(val_loader):\n",
        "        inputs, labels = inp\n",
        "        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
        "    \n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        losses.append(loss.item())\n",
        "        \n",
        "        #running_loss += loss.item()\n",
        "    avg_loss = sum(losses)/len(losses)\n",
        "    total_val_loss.append(avg_loss)\n",
        "\n",
        "  #<---------------Test Loop---------------------->\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to('cuda'), labels.to('cuda')\n",
        "        outputs = net(images)\n",
        "        \n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    score_list.append(100*(correct/total))\n",
        "    print('Accuracy test images: ', 100*(correct/total), '%')\n",
        "            \n",
        "print('Training Done')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss [1, 100](epoch, minibatch):  1.5971621894836425\n",
            "Loss [1, 200](epoch, minibatch):  1.4941417062282563\n",
            "Loss [1, 300](epoch, minibatch):  1.4611489832401277\n",
            "Loss [1, 400](epoch, minibatch):  1.4703956139087677\n",
            "Loss [1, 500](epoch, minibatch):  1.4153948521614075\n",
            "Loss [1, 600](epoch, minibatch):  1.4038525915145874\n",
            "Accuracy test images:  53.339999999999996 %\n",
            "Loss [2, 100](epoch, minibatch):  1.3879529291391373\n",
            "Loss [2, 200](epoch, minibatch):  1.348981665968895\n",
            "Loss [2, 300](epoch, minibatch):  1.3840288698673249\n",
            "Loss [2, 400](epoch, minibatch):  1.3367592334747314\n",
            "Loss [2, 500](epoch, minibatch):  1.3391355860233307\n",
            "Loss [2, 600](epoch, minibatch):  1.3631474423408507\n",
            "Accuracy test images:  54.22 %\n",
            "Loss [3, 100](epoch, minibatch):  1.4311468648910521\n",
            "Loss [3, 200](epoch, minibatch):  1.3661815655231475\n",
            "Loss [3, 300](epoch, minibatch):  1.4356723833084106\n",
            "Loss [3, 400](epoch, minibatch):  1.3662859225273132\n",
            "Loss [3, 500](epoch, minibatch):  1.471145043373108\n",
            "Loss [3, 600](epoch, minibatch):  1.5130413913726806\n",
            "Accuracy test images:  51.23 %\n",
            "Loss [4, 100](epoch, minibatch):  1.4156384360790253\n",
            "Loss [4, 200](epoch, minibatch):  1.3833219146728515\n",
            "Loss [4, 300](epoch, minibatch):  1.329828569293022\n",
            "Loss [4, 400](epoch, minibatch):  1.3098156714439393\n",
            "Loss [4, 500](epoch, minibatch):  1.2881517267227174\n",
            "Loss [4, 600](epoch, minibatch):  1.303937314748764\n",
            "Accuracy test images:  56.98 %\n",
            "Loss [5, 100](epoch, minibatch):  1.2710049551725389\n",
            "Loss [5, 200](epoch, minibatch):  1.2461182516813278\n",
            "Loss [5, 300](epoch, minibatch):  1.2635723197460174\n",
            "Loss [5, 400](epoch, minibatch):  1.2489655166864395\n",
            "Loss [5, 500](epoch, minibatch):  1.232927122116089\n",
            "Loss [5, 600](epoch, minibatch):  1.2369827270507812\n",
            "Accuracy test images:  59.9 %\n",
            "Loss [6, 100](epoch, minibatch):  1.2205075323581696\n",
            "Loss [6, 200](epoch, minibatch):  1.2321208268404007\n",
            "Loss [6, 300](epoch, minibatch):  1.2230051809549332\n",
            "Loss [6, 400](epoch, minibatch):  1.1996600264310837\n",
            "Loss [6, 500](epoch, minibatch):  1.2269641548395156\n",
            "Loss [6, 600](epoch, minibatch):  1.2197725087404252\n",
            "Accuracy test images:  61.260000000000005 %\n",
            "Loss [7, 100](epoch, minibatch):  1.1767394977808\n",
            "Loss [7, 200](epoch, minibatch):  1.1843056333065034\n",
            "Loss [7, 300](epoch, minibatch):  1.186961808204651\n",
            "Loss [7, 400](epoch, minibatch):  1.1610196185112\n",
            "Loss [7, 500](epoch, minibatch):  1.1925838160514832\n",
            "Loss [7, 600](epoch, minibatch):  1.1582465052604676\n",
            "Accuracy test images:  60.64000000000001 %\n",
            "Loss [8, 100](epoch, minibatch):  1.1482682418823242\n",
            "Loss [8, 200](epoch, minibatch):  1.141437572836876\n",
            "Loss [8, 300](epoch, minibatch):  1.146345487833023\n",
            "Loss [8, 400](epoch, minibatch):  1.1380824661254882\n",
            "Loss [8, 500](epoch, minibatch):  1.140364882349968\n",
            "Loss [8, 600](epoch, minibatch):  1.1715083956718444\n",
            "Accuracy test images:  62.07 %\n",
            "Loss [9, 100](epoch, minibatch):  1.1281792551279068\n",
            "Loss [9, 200](epoch, minibatch):  1.1134870260953904\n",
            "Loss [9, 300](epoch, minibatch):  1.0857855135202408\n",
            "Loss [9, 400](epoch, minibatch):  1.1356864827871322\n",
            "Loss [9, 500](epoch, minibatch):  1.1126219373941422\n",
            "Loss [9, 600](epoch, minibatch):  1.1280094623565673\n",
            "Accuracy test images:  62.93 %\n",
            "Loss [10, 100](epoch, minibatch):  1.101807463169098\n",
            "Loss [10, 200](epoch, minibatch):  1.102712515592575\n",
            "Loss [10, 300](epoch, minibatch):  1.0922954380512238\n",
            "Loss [10, 400](epoch, minibatch):  1.0987845158576965\n",
            "Loss [10, 500](epoch, minibatch):  1.092507340312004\n",
            "Loss [10, 600](epoch, minibatch):  1.0803571331501007\n",
            "Accuracy test images:  62.25000000000001 %\n",
            "Loss [11, 100](epoch, minibatch):  1.077636608481407\n",
            "Loss [11, 200](epoch, minibatch):  1.0797159320116043\n",
            "Loss [11, 300](epoch, minibatch):  1.085654456615448\n",
            "Loss [11, 400](epoch, minibatch):  1.0985383540391922\n",
            "Loss [11, 500](epoch, minibatch):  1.0676365900039673\n",
            "Loss [11, 600](epoch, minibatch):  1.0667798274755478\n",
            "Accuracy test images:  63.29 %\n",
            "Loss [12, 100](epoch, minibatch):  1.0573631805181503\n",
            "Loss [12, 200](epoch, minibatch):  1.0907428330183029\n",
            "Loss [12, 300](epoch, minibatch):  1.0925603103637695\n",
            "Loss [12, 400](epoch, minibatch):  1.067820646762848\n",
            "Loss [12, 500](epoch, minibatch):  1.0680574089288712\n",
            "Loss [12, 600](epoch, minibatch):  1.0761659145355225\n",
            "Accuracy test images:  65.25 %\n",
            "Loss [13, 100](epoch, minibatch):  1.0392172235250472\n",
            "Loss [13, 200](epoch, minibatch):  1.0378165131807326\n",
            "Loss [13, 300](epoch, minibatch):  1.0182354938983917\n",
            "Loss [13, 400](epoch, minibatch):  1.0330490475893022\n",
            "Loss [13, 500](epoch, minibatch):  1.057274277806282\n",
            "Loss [13, 600](epoch, minibatch):  1.0654704010486602\n",
            "Accuracy test images:  64.78 %\n",
            "Loss [14, 100](epoch, minibatch):  1.0417202162742614\n",
            "Loss [14, 200](epoch, minibatch):  1.0175569427013398\n",
            "Loss [14, 300](epoch, minibatch):  1.0118533605337143\n",
            "Loss [14, 400](epoch, minibatch):  1.0457396233081817\n",
            "Loss [14, 500](epoch, minibatch):  1.0030096220970153\n",
            "Loss [14, 600](epoch, minibatch):  1.018604633808136\n",
            "Accuracy test images:  66.06 %\n",
            "Loss [15, 100](epoch, minibatch):  0.9665746432542801\n",
            "Loss [15, 200](epoch, minibatch):  1.0323123717308045\n",
            "Loss [15, 300](epoch, minibatch):  1.0304773449897766\n",
            "Loss [15, 400](epoch, minibatch):  1.0366812497377396\n",
            "Loss [15, 500](epoch, minibatch):  1.021586121916771\n",
            "Loss [15, 600](epoch, minibatch):  1.013139361143112\n",
            "Accuracy test images:  66.73 %\n",
            "Loss [16, 100](epoch, minibatch):  1.0062484514713288\n",
            "Loss [16, 200](epoch, minibatch):  0.9929291152954102\n",
            "Loss [16, 300](epoch, minibatch):  0.9934307736158371\n",
            "Loss [16, 400](epoch, minibatch):  0.9901889473199844\n",
            "Loss [16, 500](epoch, minibatch):  1.0129225498437882\n",
            "Loss [16, 600](epoch, minibatch):  1.016212455034256\n",
            "Accuracy test images:  67.16 %\n",
            "Loss [17, 100](epoch, minibatch):  0.9801353764533997\n",
            "Loss [17, 200](epoch, minibatch):  0.9708561468124389\n",
            "Loss [17, 300](epoch, minibatch):  1.0140447050333024\n",
            "Loss [17, 400](epoch, minibatch):  0.9857242780923844\n",
            "Loss [17, 500](epoch, minibatch):  0.9711808931827545\n",
            "Loss [17, 600](epoch, minibatch):  0.9762283843755722\n",
            "Accuracy test images:  68.06 %\n",
            "Loss [18, 100](epoch, minibatch):  0.97510362803936\n",
            "Loss [18, 200](epoch, minibatch):  0.99136594414711\n",
            "Loss [18, 300](epoch, minibatch):  0.9546882003545761\n",
            "Loss [18, 400](epoch, minibatch):  0.9673302060365677\n",
            "Loss [18, 500](epoch, minibatch):  0.957027862071991\n",
            "Loss [18, 600](epoch, minibatch):  0.9596661788225174\n",
            "Accuracy test images:  69.02000000000001 %\n",
            "Loss [19, 100](epoch, minibatch):  0.960170019865036\n",
            "Loss [19, 200](epoch, minibatch):  0.9587009012699127\n",
            "Loss [19, 300](epoch, minibatch):  0.935308490395546\n",
            "Loss [19, 400](epoch, minibatch):  0.9636197179555893\n",
            "Loss [19, 500](epoch, minibatch):  0.9675949150323868\n",
            "Loss [19, 600](epoch, minibatch):  0.9610937458276748\n",
            "Accuracy test images:  69.19 %\n",
            "Loss [20, 100](epoch, minibatch):  0.9355544352531433\n",
            "Loss [20, 200](epoch, minibatch):  0.9695084887742996\n",
            "Loss [20, 300](epoch, minibatch):  0.9609580630064011\n",
            "Loss [20, 400](epoch, minibatch):  0.971878148317337\n",
            "Loss [20, 500](epoch, minibatch):  0.9296349477767945\n",
            "Loss [20, 600](epoch, minibatch):  0.9368682783842087\n",
            "Accuracy test images:  69.17 %\n",
            "Loss [21, 100](epoch, minibatch):  0.9739163619279861\n",
            "Loss [21, 200](epoch, minibatch):  0.9186634045839309\n",
            "Loss [21, 300](epoch, minibatch):  0.9438195377588272\n",
            "Loss [21, 400](epoch, minibatch):  0.9452728354930877\n",
            "Loss [21, 500](epoch, minibatch):  0.9324812710285186\n",
            "Loss [21, 600](epoch, minibatch):  0.9440362340211869\n",
            "Accuracy test images:  69.01 %\n",
            "Loss [22, 100](epoch, minibatch):  0.9306650400161743\n",
            "Loss [22, 200](epoch, minibatch):  0.9514348787069321\n",
            "Loss [22, 300](epoch, minibatch):  0.9026841205358506\n",
            "Loss [22, 400](epoch, minibatch):  0.9458232933282852\n",
            "Loss [22, 500](epoch, minibatch):  0.9657164686918258\n",
            "Loss [22, 600](epoch, minibatch):  0.9274349164962769\n",
            "Accuracy test images:  69.15 %\n",
            "Loss [23, 100](epoch, minibatch):  0.9203476005792618\n",
            "Loss [23, 200](epoch, minibatch):  0.8913933539390564\n",
            "Loss [23, 300](epoch, minibatch):  0.8966745698451996\n",
            "Loss [23, 400](epoch, minibatch):  0.9150464177131653\n",
            "Loss [23, 500](epoch, minibatch):  0.906786614060402\n",
            "Loss [23, 600](epoch, minibatch):  0.9065000283718109\n",
            "Accuracy test images:  71.69 %\n",
            "Loss [24, 100](epoch, minibatch):  0.9119221234321594\n",
            "Loss [24, 200](epoch, minibatch):  0.9184673768281937\n",
            "Loss [24, 300](epoch, minibatch):  0.8890359526872635\n",
            "Loss [24, 400](epoch, minibatch):  0.9081508708000183\n",
            "Loss [24, 500](epoch, minibatch):  0.8948088157176971\n",
            "Loss [24, 600](epoch, minibatch):  0.8833880245685577\n",
            "Accuracy test images:  69.71000000000001 %\n",
            "Loss [25, 100](epoch, minibatch):  0.8698139345645904\n",
            "Loss [25, 200](epoch, minibatch):  0.8748282045125961\n",
            "Loss [25, 300](epoch, minibatch):  0.9021440494060516\n",
            "Loss [25, 400](epoch, minibatch):  0.8882722622156143\n",
            "Loss [25, 500](epoch, minibatch):  0.909500214457512\n",
            "Loss [25, 600](epoch, minibatch):  0.8862720495462417\n",
            "Accuracy test images:  70.5 %\n",
            "Loss [26, 100](epoch, minibatch):  0.8734500801563263\n",
            "Loss [26, 200](epoch, minibatch):  0.8533012008666992\n",
            "Loss [26, 300](epoch, minibatch):  0.8317862689495087\n",
            "Loss [26, 400](epoch, minibatch):  0.9048876357078552\n",
            "Loss [26, 500](epoch, minibatch):  0.8895911169052124\n",
            "Loss [26, 600](epoch, minibatch):  0.8909096097946168\n",
            "Accuracy test images:  71.58 %\n",
            "Loss [27, 100](epoch, minibatch):  0.8716142272949219\n",
            "Loss [27, 200](epoch, minibatch):  0.8804440695047379\n",
            "Loss [27, 300](epoch, minibatch):  0.859759868979454\n",
            "Loss [27, 400](epoch, minibatch):  0.8867909669876098\n",
            "Loss [27, 500](epoch, minibatch):  0.8695970857143402\n",
            "Loss [27, 600](epoch, minibatch):  0.8867861706018448\n",
            "Accuracy test images:  70.62 %\n",
            "Loss [28, 100](epoch, minibatch):  0.8717670363187789\n",
            "Loss [28, 200](epoch, minibatch):  0.8249916648864746\n",
            "Loss [28, 300](epoch, minibatch):  0.8718785965442657\n",
            "Loss [28, 400](epoch, minibatch):  0.8500113433599472\n",
            "Loss [28, 500](epoch, minibatch):  0.8774223548173904\n",
            "Loss [28, 600](epoch, minibatch):  0.888383823633194\n",
            "Accuracy test images:  69.76 %\n",
            "Loss [29, 100](epoch, minibatch):  0.837707160115242\n",
            "Loss [29, 200](epoch, minibatch):  0.8533664220571517\n",
            "Loss [29, 300](epoch, minibatch):  0.8597594660520553\n",
            "Loss [29, 400](epoch, minibatch):  0.8596007472276688\n",
            "Loss [29, 500](epoch, minibatch):  0.8807011735439301\n",
            "Loss [29, 600](epoch, minibatch):  0.8647320389747619\n",
            "Accuracy test images:  71.04 %\n",
            "Loss [30, 100](epoch, minibatch):  0.8313026738166809\n",
            "Loss [30, 200](epoch, minibatch):  0.8411759471893311\n",
            "Loss [30, 300](epoch, minibatch):  0.861590421795845\n",
            "Loss [30, 400](epoch, minibatch):  0.8433740788698196\n",
            "Loss [30, 500](epoch, minibatch):  0.8650364261865616\n",
            "Loss [30, 600](epoch, minibatch):  0.853066349029541\n",
            "Accuracy test images:  71.1 %\n",
            "Loss [31, 100](epoch, minibatch):  0.8314187437295913\n",
            "Loss [31, 200](epoch, minibatch):  0.8418160545825958\n",
            "Loss [31, 300](epoch, minibatch):  0.8319436264038086\n",
            "Loss [31, 400](epoch, minibatch):  0.8560550594329834\n",
            "Loss [31, 500](epoch, minibatch):  0.8379803800582886\n",
            "Loss [31, 600](epoch, minibatch):  0.8664442044496536\n",
            "Accuracy test images:  73.06 %\n",
            "Loss [32, 100](epoch, minibatch):  0.8125254881381988\n",
            "Loss [32, 200](epoch, minibatch):  0.8153134191036224\n",
            "Loss [32, 300](epoch, minibatch):  0.8267239382863045\n",
            "Loss [32, 400](epoch, minibatch):  0.8348945248126983\n",
            "Loss [32, 500](epoch, minibatch):  0.8432918083667755\n",
            "Loss [32, 600](epoch, minibatch):  0.8618020075559616\n",
            "Accuracy test images:  72.65 %\n",
            "Loss [33, 100](epoch, minibatch):  0.8445204502344131\n",
            "Loss [33, 200](epoch, minibatch):  0.8186790364980697\n",
            "Loss [33, 300](epoch, minibatch):  0.8273943638801575\n",
            "Loss [33, 400](epoch, minibatch):  0.856639308333397\n",
            "Loss [33, 500](epoch, minibatch):  0.8181478297710418\n",
            "Loss [33, 600](epoch, minibatch):  0.8218802839517594\n",
            "Accuracy test images:  72.8 %\n",
            "Loss [34, 100](epoch, minibatch):  0.8257743030786514\n",
            "Loss [34, 200](epoch, minibatch):  0.7974482482671738\n",
            "Loss [34, 300](epoch, minibatch):  0.8235410231351853\n",
            "Loss [34, 400](epoch, minibatch):  0.8122638919949532\n",
            "Loss [34, 500](epoch, minibatch):  0.8362929332256317\n",
            "Loss [34, 600](epoch, minibatch):  0.8272139298915863\n",
            "Accuracy test images:  73.77 %\n",
            "Loss [35, 100](epoch, minibatch):  0.8000662821531296\n",
            "Loss [35, 200](epoch, minibatch):  0.8016340380907059\n",
            "Loss [35, 300](epoch, minibatch):  0.8368130534887314\n",
            "Loss [35, 400](epoch, minibatch):  0.8178216433525085\n",
            "Loss [35, 500](epoch, minibatch):  0.8447265404462815\n",
            "Loss [35, 600](epoch, minibatch):  0.8450997996330262\n",
            "Accuracy test images:  73.41 %\n",
            "Loss [36, 100](epoch, minibatch):  0.8272423791885376\n",
            "Loss [36, 200](epoch, minibatch):  0.8038762459158897\n",
            "Loss [36, 300](epoch, minibatch):  0.8492466849088669\n",
            "Loss [36, 400](epoch, minibatch):  0.8369832122325898\n",
            "Loss [36, 500](epoch, minibatch):  0.816768079996109\n",
            "Loss [36, 600](epoch, minibatch):  0.802354673743248\n",
            "Accuracy test images:  74.06 %\n",
            "Loss [37, 100](epoch, minibatch):  0.8046474623680114\n",
            "Loss [37, 200](epoch, minibatch):  0.8052469348907471\n",
            "Loss [37, 300](epoch, minibatch):  0.8200927197933197\n",
            "Loss [37, 400](epoch, minibatch):  0.8062059864401817\n",
            "Loss [37, 500](epoch, minibatch):  0.7997270959615708\n",
            "Loss [37, 600](epoch, minibatch):  0.7874444156885148\n",
            "Accuracy test images:  72.87 %\n",
            "Loss [38, 100](epoch, minibatch):  0.8279054600000382\n",
            "Loss [38, 200](epoch, minibatch):  0.7866719248890877\n",
            "Loss [38, 300](epoch, minibatch):  0.7881602841615677\n",
            "Loss [38, 400](epoch, minibatch):  0.8092773818969726\n",
            "Loss [38, 500](epoch, minibatch):  0.8200174066424369\n",
            "Loss [38, 600](epoch, minibatch):  0.8026792329549789\n",
            "Accuracy test images:  73.96000000000001 %\n",
            "Loss [39, 100](epoch, minibatch):  0.7828456139564515\n",
            "Loss [39, 200](epoch, minibatch):  0.8162597650289536\n",
            "Loss [39, 300](epoch, minibatch):  0.7726135167479515\n",
            "Loss [39, 400](epoch, minibatch):  0.8113902544975281\n",
            "Loss [39, 500](epoch, minibatch):  0.8150858613848686\n",
            "Loss [39, 600](epoch, minibatch):  0.7869146654009819\n",
            "Accuracy test images:  72.64 %\n",
            "Loss [40, 100](epoch, minibatch):  0.7674695411324501\n",
            "Loss [40, 200](epoch, minibatch):  0.7787722471356392\n",
            "Loss [40, 300](epoch, minibatch):  0.8093223941326141\n",
            "Loss [40, 400](epoch, minibatch):  0.7883986961841584\n",
            "Loss [40, 500](epoch, minibatch):  0.7987236732244491\n",
            "Loss [40, 600](epoch, minibatch):  0.798296565413475\n",
            "Accuracy test images:  73.74000000000001 %\n",
            "Loss [41, 100](epoch, minibatch):  0.7961080804467201\n",
            "Loss [41, 200](epoch, minibatch):  0.7923745840787888\n",
            "Loss [41, 300](epoch, minibatch):  0.7931473577022552\n",
            "Loss [41, 400](epoch, minibatch):  0.7958420538902282\n",
            "Loss [41, 500](epoch, minibatch):  0.7771262234449386\n",
            "Loss [41, 600](epoch, minibatch):  0.8041927149891853\n",
            "Accuracy test images:  73.61 %\n",
            "Loss [42, 100](epoch, minibatch):  0.7818321469426155\n",
            "Loss [42, 200](epoch, minibatch):  0.7975969159603119\n",
            "Loss [42, 300](epoch, minibatch):  0.8161860305070877\n",
            "Loss [42, 400](epoch, minibatch):  0.7698862689733506\n",
            "Loss [42, 500](epoch, minibatch):  0.7855568012595177\n",
            "Loss [42, 600](epoch, minibatch):  0.7676595920324325\n",
            "Accuracy test images:  73.98 %\n",
            "Loss [43, 100](epoch, minibatch):  0.7821411472558976\n",
            "Loss [43, 200](epoch, minibatch):  0.791657361984253\n",
            "Loss [43, 300](epoch, minibatch):  0.7697635525465012\n",
            "Loss [43, 400](epoch, minibatch):  0.7886634656786918\n",
            "Loss [43, 500](epoch, minibatch):  0.7836662620306015\n",
            "Loss [43, 600](epoch, minibatch):  0.7952257314324379\n",
            "Accuracy test images:  74.2 %\n",
            "Loss [44, 100](epoch, minibatch):  0.7760998558998108\n",
            "Loss [44, 200](epoch, minibatch):  0.792623618543148\n",
            "Loss [44, 300](epoch, minibatch):  0.7986515721678734\n",
            "Loss [44, 400](epoch, minibatch):  0.7886856627464295\n",
            "Loss [44, 500](epoch, minibatch):  0.7741254553198814\n",
            "Loss [44, 600](epoch, minibatch):  0.7912498009204865\n",
            "Accuracy test images:  74.67 %\n",
            "Loss [45, 100](epoch, minibatch):  0.7717972981929779\n",
            "Loss [45, 200](epoch, minibatch):  0.7723937022686005\n",
            "Loss [45, 300](epoch, minibatch):  0.7788671937584877\n",
            "Loss [45, 400](epoch, minibatch):  0.7965485537052155\n",
            "Loss [45, 500](epoch, minibatch):  0.7807467874884605\n",
            "Loss [45, 600](epoch, minibatch):  0.7776007610559463\n",
            "Accuracy test images:  72.52 %\n",
            "Loss [46, 100](epoch, minibatch):  0.7839712780714035\n",
            "Loss [46, 200](epoch, minibatch):  0.7673472428321838\n",
            "Loss [46, 300](epoch, minibatch):  0.7709766352176666\n",
            "Loss [46, 400](epoch, minibatch):  0.7761108273267746\n",
            "Loss [46, 500](epoch, minibatch):  0.7945634585618973\n",
            "Loss [46, 600](epoch, minibatch):  0.7907597279548645\n",
            "Accuracy test images:  74.51 %\n",
            "Loss [47, 100](epoch, minibatch):  0.7531917008757592\n",
            "Loss [47, 200](epoch, minibatch):  0.7473078745603562\n",
            "Loss [47, 300](epoch, minibatch):  0.7791311168670654\n",
            "Loss [47, 400](epoch, minibatch):  0.7846883741021157\n",
            "Loss [47, 500](epoch, minibatch):  0.7915459552407265\n",
            "Loss [47, 600](epoch, minibatch):  0.785330725312233\n",
            "Accuracy test images:  73.99 %\n",
            "Loss [48, 100](epoch, minibatch):  0.7721685141324997\n",
            "Loss [48, 200](epoch, minibatch):  0.7418180361390114\n",
            "Loss [48, 300](epoch, minibatch):  0.7614991056919098\n",
            "Loss [48, 400](epoch, minibatch):  0.7730129837989808\n",
            "Loss [48, 500](epoch, minibatch):  0.7887894701957703\n",
            "Loss [48, 600](epoch, minibatch):  0.7719462135434151\n",
            "Accuracy test images:  74.53 %\n",
            "Loss [49, 100](epoch, minibatch):  0.7478412342071533\n",
            "Loss [49, 200](epoch, minibatch):  0.7566546857357025\n",
            "Loss [49, 300](epoch, minibatch):  0.7564496722817421\n",
            "Loss [49, 400](epoch, minibatch):  0.7605870282649994\n",
            "Loss [49, 500](epoch, minibatch):  0.7551749107241631\n",
            "Loss [49, 600](epoch, minibatch):  0.7736499065160751\n",
            "Accuracy test images:  72.92 %\n",
            "Loss [50, 100](epoch, minibatch):  0.7611604204773903\n",
            "Loss [50, 200](epoch, minibatch):  0.751990941464901\n",
            "Loss [50, 300](epoch, minibatch):  0.7638886785507202\n",
            "Loss [50, 400](epoch, minibatch):  0.7544056344032287\n",
            "Loss [50, 500](epoch, minibatch):  0.7804021766781807\n",
            "Loss [50, 600](epoch, minibatch):  0.7395741519331932\n",
            "Accuracy test images:  75.03 %\n",
            "Loss [51, 100](epoch, minibatch):  0.7451297703385353\n",
            "Loss [51, 200](epoch, minibatch):  0.759061809182167\n",
            "Loss [51, 300](epoch, minibatch):  0.7646558114886284\n",
            "Loss [51, 400](epoch, minibatch):  0.7604828289151192\n",
            "Loss [51, 500](epoch, minibatch):  0.721395306289196\n",
            "Loss [51, 600](epoch, minibatch):  0.7544265231490135\n",
            "Accuracy test images:  74.5 %\n",
            "Loss [52, 100](epoch, minibatch):  0.7475500279664993\n",
            "Loss [52, 200](epoch, minibatch):  0.7332024854421616\n",
            "Loss [52, 300](epoch, minibatch):  0.7614016669988632\n",
            "Loss [52, 400](epoch, minibatch):  0.7615609914064407\n",
            "Loss [52, 500](epoch, minibatch):  0.7649747836589813\n",
            "Loss [52, 600](epoch, minibatch):  0.7526649078726768\n",
            "Accuracy test images:  74.85000000000001 %\n",
            "Loss [53, 100](epoch, minibatch):  0.7412113100290298\n",
            "Loss [53, 200](epoch, minibatch):  0.7464463952183723\n",
            "Loss [53, 300](epoch, minibatch):  0.7712443029880524\n",
            "Loss [53, 400](epoch, minibatch):  0.7573016339540481\n",
            "Loss [53, 500](epoch, minibatch):  0.7460658359527588\n",
            "Loss [53, 600](epoch, minibatch):  0.745566877424717\n",
            "Accuracy test images:  74.27 %\n",
            "Loss [54, 100](epoch, minibatch):  0.7580035719275474\n",
            "Loss [54, 200](epoch, minibatch):  0.7504498013854026\n",
            "Loss [54, 300](epoch, minibatch):  0.7338333606719971\n",
            "Loss [54, 400](epoch, minibatch):  0.7407709383964538\n",
            "Loss [54, 500](epoch, minibatch):  0.7378511989116668\n",
            "Loss [54, 600](epoch, minibatch):  0.752954494357109\n",
            "Accuracy test images:  74.24 %\n",
            "Loss [55, 100](epoch, minibatch):  0.734627310037613\n",
            "Loss [55, 200](epoch, minibatch):  0.7323665109276771\n",
            "Loss [55, 300](epoch, minibatch):  0.7553705254197121\n",
            "Loss [55, 400](epoch, minibatch):  0.7714382109045982\n",
            "Loss [55, 500](epoch, minibatch):  0.7708399593830109\n",
            "Loss [55, 600](epoch, minibatch):  0.7400297141075134\n",
            "Accuracy test images:  74.35000000000001 %\n",
            "Loss [56, 100](epoch, minibatch):  0.7364366114139557\n",
            "Loss [56, 200](epoch, minibatch):  0.739633960723877\n",
            "Loss [56, 300](epoch, minibatch):  0.7413115790486335\n",
            "Loss [56, 400](epoch, minibatch):  0.7322711917757988\n",
            "Loss [56, 500](epoch, minibatch):  0.7460641610622406\n",
            "Loss [56, 600](epoch, minibatch):  0.7478103044629097\n",
            "Accuracy test images:  75.5 %\n",
            "Loss [57, 100](epoch, minibatch):  0.7358024042844772\n",
            "Loss [57, 200](epoch, minibatch):  0.7311095184087754\n",
            "Loss [57, 300](epoch, minibatch):  0.7405405157804489\n",
            "Loss [57, 400](epoch, minibatch):  0.729940796494484\n",
            "Loss [57, 500](epoch, minibatch):  0.7410424992442131\n",
            "Loss [57, 600](epoch, minibatch):  0.7379546809196472\n",
            "Accuracy test images:  74.72 %\n",
            "Loss [58, 100](epoch, minibatch):  0.7534437879920006\n",
            "Loss [58, 200](epoch, minibatch):  0.7124257639050484\n",
            "Loss [58, 300](epoch, minibatch):  0.7314520788192749\n",
            "Loss [58, 400](epoch, minibatch):  0.7444987452030182\n",
            "Loss [58, 500](epoch, minibatch):  0.725579881966114\n",
            "Loss [58, 600](epoch, minibatch):  0.7463848036527634\n",
            "Accuracy test images:  75.49 %\n",
            "Loss [59, 100](epoch, minibatch):  0.7311908859014511\n",
            "Loss [59, 200](epoch, minibatch):  0.7311108076572418\n",
            "Loss [59, 300](epoch, minibatch):  0.7282600396871567\n",
            "Loss [59, 400](epoch, minibatch):  0.7434681048989296\n",
            "Loss [59, 500](epoch, minibatch):  0.7412686282396317\n",
            "Loss [59, 600](epoch, minibatch):  0.7474438244104386\n",
            "Accuracy test images:  75.13 %\n",
            "Loss [60, 100](epoch, minibatch):  0.7266339614987374\n",
            "Loss [60, 200](epoch, minibatch):  0.7383015376329422\n",
            "Loss [60, 300](epoch, minibatch):  0.7293709605932236\n",
            "Loss [60, 400](epoch, minibatch):  0.7311263102293014\n",
            "Loss [60, 500](epoch, minibatch):  0.7381304720044136\n",
            "Loss [60, 600](epoch, minibatch):  0.7467760318517684\n",
            "Accuracy test images:  75.03 %\n",
            "Loss [61, 100](epoch, minibatch):  0.7315489247441291\n",
            "Loss [61, 200](epoch, minibatch):  0.7084853494167328\n",
            "Loss [61, 300](epoch, minibatch):  0.7248432654142379\n",
            "Loss [61, 400](epoch, minibatch):  0.7305956128239631\n",
            "Loss [61, 500](epoch, minibatch):  0.7104341968894005\n",
            "Loss [61, 600](epoch, minibatch):  0.7505710732936859\n",
            "Accuracy test images:  75.01 %\n",
            "Loss [62, 100](epoch, minibatch):  0.7298990309238433\n",
            "Loss [62, 200](epoch, minibatch):  0.7558847984671593\n",
            "Loss [62, 300](epoch, minibatch):  0.7077417227625847\n",
            "Loss [62, 400](epoch, minibatch):  0.7353213649988174\n",
            "Loss [62, 500](epoch, minibatch):  0.7340252017974853\n",
            "Loss [62, 600](epoch, minibatch):  0.7267874532938003\n",
            "Accuracy test images:  76.98 %\n",
            "Loss [63, 100](epoch, minibatch):  0.7115659636259078\n",
            "Loss [63, 200](epoch, minibatch):  0.7295113635063172\n",
            "Loss [63, 300](epoch, minibatch):  0.7372059595584869\n",
            "Loss [63, 400](epoch, minibatch):  0.7377282610535622\n",
            "Loss [63, 500](epoch, minibatch):  0.7040490105748176\n",
            "Loss [63, 600](epoch, minibatch):  0.721859188079834\n",
            "Accuracy test images:  75.8 %\n",
            "Loss [64, 100](epoch, minibatch):  0.7113967028260231\n",
            "Loss [64, 200](epoch, minibatch):  0.6984608152508736\n",
            "Loss [64, 300](epoch, minibatch):  0.709403318464756\n",
            "Loss [64, 400](epoch, minibatch):  0.7176119720935822\n",
            "Loss [64, 500](epoch, minibatch):  0.7171743294596672\n",
            "Loss [64, 600](epoch, minibatch):  0.7512708681821824\n",
            "Accuracy test images:  75.75 %\n",
            "Loss [65, 100](epoch, minibatch):  0.7335341489315033\n",
            "Loss [65, 200](epoch, minibatch):  0.7162031549215316\n",
            "Loss [65, 300](epoch, minibatch):  0.7144637590646744\n",
            "Loss [65, 400](epoch, minibatch):  0.7096772250533104\n",
            "Loss [65, 500](epoch, minibatch):  0.6948296803236008\n",
            "Loss [65, 600](epoch, minibatch):  0.7453394672274589\n",
            "Accuracy test images:  75.66000000000001 %\n",
            "Loss [66, 100](epoch, minibatch):  0.7129752844572067\n",
            "Loss [66, 200](epoch, minibatch):  0.6974184709787369\n",
            "Loss [66, 300](epoch, minibatch):  0.722389622926712\n",
            "Loss [66, 400](epoch, minibatch):  0.7004891958832741\n",
            "Loss [66, 500](epoch, minibatch):  0.7332453605532646\n",
            "Loss [66, 600](epoch, minibatch):  0.71856610506773\n",
            "Accuracy test images:  76.8 %\n",
            "Loss [67, 100](epoch, minibatch):  0.6992354744672775\n",
            "Loss [67, 200](epoch, minibatch):  0.7349201181530952\n",
            "Loss [67, 300](epoch, minibatch):  0.7113746690750122\n",
            "Loss [67, 400](epoch, minibatch):  0.6943506479263306\n",
            "Loss [67, 500](epoch, minibatch):  0.7220895254611969\n",
            "Loss [67, 600](epoch, minibatch):  0.7305677393078804\n",
            "Accuracy test images:  75.91 %\n",
            "Loss [68, 100](epoch, minibatch):  0.6912234011292457\n",
            "Loss [68, 200](epoch, minibatch):  0.7123349833488465\n",
            "Loss [68, 300](epoch, minibatch):  0.7030694246292114\n",
            "Loss [68, 400](epoch, minibatch):  0.7214960592985153\n",
            "Loss [68, 500](epoch, minibatch):  0.7141308861970902\n",
            "Loss [68, 600](epoch, minibatch):  0.7263268953561783\n",
            "Accuracy test images:  76.03 %\n",
            "Loss [69, 100](epoch, minibatch):  0.7196311631798744\n",
            "Loss [69, 200](epoch, minibatch):  0.7119940686225891\n",
            "Loss [69, 300](epoch, minibatch):  0.6855014514923096\n",
            "Loss [69, 400](epoch, minibatch):  0.7286574256420135\n",
            "Loss [69, 500](epoch, minibatch):  0.7065486252307892\n",
            "Loss [69, 600](epoch, minibatch):  0.7253196880221366\n",
            "Accuracy test images:  75.44999999999999 %\n",
            "Loss [70, 100](epoch, minibatch):  0.721961105465889\n",
            "Loss [70, 200](epoch, minibatch):  0.6950730541348458\n",
            "Loss [70, 300](epoch, minibatch):  0.6853558838367462\n",
            "Loss [70, 400](epoch, minibatch):  0.7178809595108032\n",
            "Loss [70, 500](epoch, minibatch):  0.7251775959134101\n",
            "Loss [70, 600](epoch, minibatch):  0.7124928838014603\n",
            "Accuracy test images:  75.33999999999999 %\n",
            "Loss [71, 100](epoch, minibatch):  0.7042568242549896\n",
            "Loss [71, 200](epoch, minibatch):  0.697354881465435\n",
            "Loss [71, 300](epoch, minibatch):  0.7050127267837525\n",
            "Loss [71, 400](epoch, minibatch):  0.7203498804569244\n",
            "Loss [71, 500](epoch, minibatch):  0.7201864606142044\n",
            "Loss [71, 600](epoch, minibatch):  0.7123624828457832\n",
            "Accuracy test images:  75.03999999999999 %\n",
            "Loss [72, 100](epoch, minibatch):  0.6861454370617867\n",
            "Loss [72, 200](epoch, minibatch):  0.6895664548873901\n",
            "Loss [72, 300](epoch, minibatch):  0.6801079380512237\n",
            "Loss [72, 400](epoch, minibatch):  0.7283340936899185\n",
            "Loss [72, 500](epoch, minibatch):  0.7126671501994133\n",
            "Loss [72, 600](epoch, minibatch):  0.7080764698982239\n",
            "Accuracy test images:  75.12 %\n",
            "Loss [73, 100](epoch, minibatch):  0.6963453975319862\n",
            "Loss [73, 200](epoch, minibatch):  0.6873463067412376\n",
            "Loss [73, 300](epoch, minibatch):  0.6936814463138581\n",
            "Loss [73, 400](epoch, minibatch):  0.6982193177938462\n",
            "Loss [73, 500](epoch, minibatch):  0.7379428148269653\n",
            "Loss [73, 600](epoch, minibatch):  0.7111012837290764\n",
            "Accuracy test images:  76.37 %\n",
            "Loss [74, 100](epoch, minibatch):  0.6901968818902969\n",
            "Loss [74, 200](epoch, minibatch):  0.6966936883330345\n",
            "Loss [74, 300](epoch, minibatch):  0.6854571065306664\n",
            "Loss [74, 400](epoch, minibatch):  0.7192990270256996\n",
            "Loss [74, 500](epoch, minibatch):  0.6885712331533432\n",
            "Loss [74, 600](epoch, minibatch):  0.7149882447719574\n",
            "Accuracy test images:  76.18 %\n",
            "Loss [75, 100](epoch, minibatch):  0.6718674072623253\n",
            "Loss [75, 200](epoch, minibatch):  0.711915397644043\n",
            "Loss [75, 300](epoch, minibatch):  0.6956966942548752\n",
            "Loss [75, 400](epoch, minibatch):  0.6873897621035576\n",
            "Loss [75, 500](epoch, minibatch):  0.717122394144535\n",
            "Loss [75, 600](epoch, minibatch):  0.6915130072832107\n",
            "Accuracy test images:  76.28 %\n",
            "Loss [76, 100](epoch, minibatch):  0.6820174118876458\n",
            "Loss [76, 200](epoch, minibatch):  0.6816974592208862\n",
            "Loss [76, 300](epoch, minibatch):  0.6784749114513398\n",
            "Loss [76, 400](epoch, minibatch):  0.7038575851917267\n",
            "Loss [76, 500](epoch, minibatch):  0.7089746391773224\n",
            "Loss [76, 600](epoch, minibatch):  0.7083794996142387\n",
            "Accuracy test images:  75.89 %\n",
            "Loss [77, 100](epoch, minibatch):  0.6963789770007134\n",
            "Loss [77, 200](epoch, minibatch):  0.6792239621281624\n",
            "Loss [77, 300](epoch, minibatch):  0.6972466185688972\n",
            "Loss [77, 400](epoch, minibatch):  0.7123805180191993\n",
            "Loss [77, 500](epoch, minibatch):  0.7095311647653579\n",
            "Loss [77, 600](epoch, minibatch):  0.6940042412281037\n",
            "Accuracy test images:  75.85 %\n",
            "Loss [78, 100](epoch, minibatch):  0.6992864072322845\n",
            "Loss [78, 200](epoch, minibatch):  0.690258761048317\n",
            "Loss [78, 300](epoch, minibatch):  0.6770138701796532\n",
            "Loss [78, 400](epoch, minibatch):  0.6802684623003006\n",
            "Loss [78, 500](epoch, minibatch):  0.6827707225084305\n",
            "Loss [78, 600](epoch, minibatch):  0.7184965005517006\n",
            "Accuracy test images:  75.41 %\n",
            "Loss [79, 100](epoch, minibatch):  0.6836491683125496\n",
            "Loss [79, 200](epoch, minibatch):  0.6510492873191833\n",
            "Loss [79, 300](epoch, minibatch):  0.7017188900709153\n",
            "Loss [79, 400](epoch, minibatch):  0.7011240100860596\n",
            "Loss [79, 500](epoch, minibatch):  0.7184771877527237\n",
            "Loss [79, 600](epoch, minibatch):  0.7000793904066086\n",
            "Accuracy test images:  74.62 %\n",
            "Loss [80, 100](epoch, minibatch):  0.6886602324247361\n",
            "Loss [80, 200](epoch, minibatch):  0.6860729211568832\n",
            "Loss [80, 300](epoch, minibatch):  0.6859489515423774\n",
            "Loss [80, 400](epoch, minibatch):  0.6891283449530602\n",
            "Loss [80, 500](epoch, minibatch):  0.6920825868844986\n",
            "Loss [80, 600](epoch, minibatch):  0.6938672405481339\n",
            "Accuracy test images:  75.29 %\n",
            "Loss [81, 100](epoch, minibatch):  0.6716633272171021\n",
            "Loss [81, 200](epoch, minibatch):  0.6948949560523033\n",
            "Loss [81, 300](epoch, minibatch):  0.7016232481598854\n",
            "Loss [81, 400](epoch, minibatch):  0.6901931238174438\n",
            "Loss [81, 500](epoch, minibatch):  0.6879995846748352\n",
            "Loss [81, 600](epoch, minibatch):  0.6913569033145904\n",
            "Accuracy test images:  76.25 %\n",
            "Loss [82, 100](epoch, minibatch):  0.6996240842342377\n",
            "Loss [82, 200](epoch, minibatch):  0.6654816284775734\n",
            "Loss [82, 300](epoch, minibatch):  0.6805868616700173\n",
            "Loss [82, 400](epoch, minibatch):  0.6948163634538651\n",
            "Loss [82, 500](epoch, minibatch):  0.6987788972258567\n",
            "Loss [82, 600](epoch, minibatch):  0.6802288123965263\n",
            "Accuracy test images:  76.86 %\n",
            "Loss [83, 100](epoch, minibatch):  0.6816922879219055\n",
            "Loss [83, 200](epoch, minibatch):  0.6564422339200974\n",
            "Loss [83, 300](epoch, minibatch):  0.6895063090324401\n",
            "Loss [83, 400](epoch, minibatch):  0.678128190934658\n",
            "Loss [83, 500](epoch, minibatch):  0.6935385578870773\n",
            "Loss [83, 600](epoch, minibatch):  0.688043437898159\n",
            "Accuracy test images:  75.83 %\n",
            "Loss [84, 100](epoch, minibatch):  0.6888233929872513\n",
            "Loss [84, 200](epoch, minibatch):  0.6727927580475808\n",
            "Loss [84, 300](epoch, minibatch):  0.6794147717952729\n",
            "Loss [84, 400](epoch, minibatch):  0.6822868722677231\n",
            "Loss [84, 500](epoch, minibatch):  0.7008979392051696\n",
            "Loss [84, 600](epoch, minibatch):  0.6867725703120232\n",
            "Accuracy test images:  76.19 %\n",
            "Loss [85, 100](epoch, minibatch):  0.6935746395587921\n",
            "Loss [85, 200](epoch, minibatch):  0.6898795127868652\n",
            "Loss [85, 300](epoch, minibatch):  0.6699712669849396\n",
            "Loss [85, 400](epoch, minibatch):  0.6756813266873359\n",
            "Loss [85, 500](epoch, minibatch):  0.6848888173699379\n",
            "Loss [85, 600](epoch, minibatch):  0.6830447739362717\n",
            "Accuracy test images:  75.44 %\n",
            "Loss [86, 100](epoch, minibatch):  0.6586473992466927\n",
            "Loss [86, 200](epoch, minibatch):  0.6928585529327392\n",
            "Loss [86, 300](epoch, minibatch):  0.6628316035866737\n",
            "Loss [86, 400](epoch, minibatch):  0.7061805558204651\n",
            "Loss [86, 500](epoch, minibatch):  0.6909516683220863\n",
            "Loss [86, 600](epoch, minibatch):  0.711758753657341\n",
            "Accuracy test images:  75.83 %\n",
            "Loss [87, 100](epoch, minibatch):  0.6744514411687851\n",
            "Loss [87, 200](epoch, minibatch):  0.6699692732095719\n",
            "Loss [87, 300](epoch, minibatch):  0.680346536040306\n",
            "Loss [87, 400](epoch, minibatch):  0.6601278692483902\n",
            "Loss [87, 500](epoch, minibatch):  0.6683797040581703\n",
            "Loss [87, 600](epoch, minibatch):  0.6943618151545524\n",
            "Accuracy test images:  76.85 %\n",
            "Loss [88, 100](epoch, minibatch):  0.6845124438405037\n",
            "Loss [88, 200](epoch, minibatch):  0.6655621978640557\n",
            "Loss [88, 300](epoch, minibatch):  0.6936242592334747\n",
            "Loss [88, 400](epoch, minibatch):  0.6579163932800293\n",
            "Loss [88, 500](epoch, minibatch):  0.6933449202775955\n",
            "Loss [88, 600](epoch, minibatch):  0.6836668768525124\n",
            "Accuracy test images:  75.85 %\n",
            "Loss [89, 100](epoch, minibatch):  0.6914093613624572\n",
            "Loss [89, 200](epoch, minibatch):  0.6500433942675591\n",
            "Loss [89, 300](epoch, minibatch):  0.6691592076420784\n",
            "Loss [89, 400](epoch, minibatch):  0.6754247146844864\n",
            "Loss [89, 500](epoch, minibatch):  0.6859925252199173\n",
            "Loss [89, 600](epoch, minibatch):  0.6990443322062493\n",
            "Accuracy test images:  76.25 %\n",
            "Loss [90, 100](epoch, minibatch):  0.6810950481891632\n",
            "Loss [90, 200](epoch, minibatch):  0.6738396087288856\n",
            "Loss [90, 300](epoch, minibatch):  0.6921140280365944\n",
            "Loss [90, 400](epoch, minibatch):  0.6715699625015259\n",
            "Loss [90, 500](epoch, minibatch):  0.6719681304693222\n",
            "Loss [90, 600](epoch, minibatch):  0.6792398586869239\n",
            "Accuracy test images:  76.55999999999999 %\n",
            "Loss [91, 100](epoch, minibatch):  0.6706944039463997\n",
            "Loss [91, 200](epoch, minibatch):  0.6589715415239334\n",
            "Loss [91, 300](epoch, minibatch):  0.6805743017792701\n",
            "Loss [91, 400](epoch, minibatch):  0.6781660476326943\n",
            "Loss [91, 500](epoch, minibatch):  0.6817393639683723\n",
            "Loss [91, 600](epoch, minibatch):  0.6758421820402145\n",
            "Accuracy test images:  76.59 %\n",
            "Loss [92, 100](epoch, minibatch):  0.6749762174487114\n",
            "Loss [92, 200](epoch, minibatch):  0.6684656709432601\n",
            "Loss [92, 300](epoch, minibatch):  0.677844797372818\n",
            "Loss [92, 400](epoch, minibatch):  0.6947644236683845\n",
            "Loss [92, 500](epoch, minibatch):  0.6732443770766259\n",
            "Loss [92, 600](epoch, minibatch):  0.692780160009861\n",
            "Accuracy test images:  76.83 %\n",
            "Loss [93, 100](epoch, minibatch):  0.6666498658061027\n",
            "Loss [93, 200](epoch, minibatch):  0.654401341676712\n",
            "Loss [93, 300](epoch, minibatch):  0.6643070670962333\n",
            "Loss [93, 400](epoch, minibatch):  0.669870218038559\n",
            "Loss [93, 500](epoch, minibatch):  0.6951692259311676\n",
            "Loss [93, 600](epoch, minibatch):  0.6891563880443573\n",
            "Accuracy test images:  75.77000000000001 %\n",
            "Loss [94, 100](epoch, minibatch):  0.6521002846956253\n",
            "Loss [94, 200](epoch, minibatch):  0.6618466287851333\n",
            "Loss [94, 300](epoch, minibatch):  0.6742706137895584\n",
            "Loss [94, 400](epoch, minibatch):  0.6653958091139793\n",
            "Loss [94, 500](epoch, minibatch):  0.6910557025671005\n",
            "Loss [94, 600](epoch, minibatch):  0.6633299535512924\n",
            "Accuracy test images:  77.03999999999999 %\n",
            "Loss [95, 100](epoch, minibatch):  0.6285445329546928\n",
            "Loss [95, 200](epoch, minibatch):  0.6525967261195182\n",
            "Loss [95, 300](epoch, minibatch):  0.6750172328948975\n",
            "Loss [95, 400](epoch, minibatch):  0.6579938465356827\n",
            "Loss [95, 500](epoch, minibatch):  0.672762025296688\n",
            "Loss [95, 600](epoch, minibatch):  0.6998034414649009\n",
            "Accuracy test images:  76.03 %\n",
            "Loss [96, 100](epoch, minibatch):  0.6640121486783027\n",
            "Loss [96, 200](epoch, minibatch):  0.6873949825763702\n",
            "Loss [96, 300](epoch, minibatch):  0.6740034058690071\n",
            "Loss [96, 400](epoch, minibatch):  0.6672197097539901\n",
            "Loss [96, 500](epoch, minibatch):  0.6640189954638481\n",
            "Loss [96, 600](epoch, minibatch):  0.6744797340035439\n",
            "Accuracy test images:  75.87 %\n",
            "Loss [97, 100](epoch, minibatch):  0.6685684269666672\n",
            "Loss [97, 200](epoch, minibatch):  0.6665799421072006\n",
            "Loss [97, 300](epoch, minibatch):  0.6709178665280342\n",
            "Loss [97, 400](epoch, minibatch):  0.6672485163807869\n",
            "Loss [97, 500](epoch, minibatch):  0.6652590760588646\n",
            "Loss [97, 600](epoch, minibatch):  0.663944188952446\n",
            "Accuracy test images:  76.38000000000001 %\n",
            "Loss [98, 100](epoch, minibatch):  0.6456136578321456\n",
            "Loss [98, 200](epoch, minibatch):  0.6828771594166756\n",
            "Loss [98, 300](epoch, minibatch):  0.6662374657392501\n",
            "Loss [98, 400](epoch, minibatch):  0.6723339265584946\n",
            "Loss [98, 500](epoch, minibatch):  0.6786386421322823\n",
            "Loss [98, 600](epoch, minibatch):  0.6509455952048302\n",
            "Accuracy test images:  76.55999999999999 %\n",
            "Loss [99, 100](epoch, minibatch):  0.6380854672193528\n",
            "Loss [99, 200](epoch, minibatch):  0.6679058936238289\n",
            "Loss [99, 300](epoch, minibatch):  0.677115076482296\n",
            "Loss [99, 400](epoch, minibatch):  0.6661832961440086\n",
            "Loss [99, 500](epoch, minibatch):  0.6721161535382271\n",
            "Loss [99, 600](epoch, minibatch):  0.672100214958191\n",
            "Accuracy test images:  74.87 %\n",
            "Loss [100, 100](epoch, minibatch):  0.661806620657444\n",
            "Loss [100, 200](epoch, minibatch):  0.6615022054314613\n",
            "Loss [100, 300](epoch, minibatch):  0.6691419440507889\n",
            "Loss [100, 400](epoch, minibatch):  0.6876871165633202\n",
            "Loss [100, 500](epoch, minibatch):  0.6680286356806755\n",
            "Loss [100, 600](epoch, minibatch):  0.6603379327058793\n",
            "Accuracy test images:  77.78 %\n",
            "Loss [101, 100](epoch, minibatch):  0.655285285115242\n",
            "Loss [101, 200](epoch, minibatch):  0.653681426346302\n",
            "Loss [101, 300](epoch, minibatch):  0.6845343473553658\n",
            "Loss [101, 400](epoch, minibatch):  0.6590114343166351\n",
            "Loss [101, 500](epoch, minibatch):  0.6704926481842994\n",
            "Loss [101, 600](epoch, minibatch):  0.6784472435712814\n",
            "Accuracy test images:  76.13 %\n",
            "Loss [102, 100](epoch, minibatch):  0.6486348885297776\n",
            "Loss [102, 200](epoch, minibatch):  0.65670405626297\n",
            "Loss [102, 300](epoch, minibatch):  0.6570097202062607\n",
            "Loss [102, 400](epoch, minibatch):  0.659645502269268\n",
            "Loss [102, 500](epoch, minibatch):  0.6812876975536346\n",
            "Loss [102, 600](epoch, minibatch):  0.6549474450945855\n",
            "Accuracy test images:  76.92999999999999 %\n",
            "Loss [103, 100](epoch, minibatch):  0.6476319968700409\n",
            "Loss [103, 200](epoch, minibatch):  0.6495369243621826\n",
            "Loss [103, 300](epoch, minibatch):  0.6681024506688118\n",
            "Loss [103, 400](epoch, minibatch):  0.667180643081665\n",
            "Loss [103, 500](epoch, minibatch):  0.6670855128765106\n",
            "Loss [103, 600](epoch, minibatch):  0.6718241250514985\n",
            "Accuracy test images:  76.22 %\n",
            "Loss [104, 100](epoch, minibatch):  0.6405881914496422\n",
            "Loss [104, 200](epoch, minibatch):  0.665946653187275\n",
            "Loss [104, 300](epoch, minibatch):  0.6775377321243287\n",
            "Loss [104, 400](epoch, minibatch):  0.653335896730423\n",
            "Loss [104, 500](epoch, minibatch):  0.6828743115067482\n",
            "Loss [104, 600](epoch, minibatch):  0.6386575728654862\n",
            "Accuracy test images:  75.28 %\n",
            "Loss [105, 100](epoch, minibatch):  0.6586114329099655\n",
            "Loss [105, 200](epoch, minibatch):  0.6606895685195923\n",
            "Loss [105, 300](epoch, minibatch):  0.6607216683030128\n",
            "Loss [105, 400](epoch, minibatch):  0.6556027701497078\n",
            "Loss [105, 500](epoch, minibatch):  0.6584539705514908\n",
            "Loss [105, 600](epoch, minibatch):  0.6736323866248131\n",
            "Accuracy test images:  77.33 %\n",
            "Loss [106, 100](epoch, minibatch):  0.6517025426030159\n",
            "Loss [106, 200](epoch, minibatch):  0.6583712056279183\n",
            "Loss [106, 300](epoch, minibatch):  0.6564972791075706\n",
            "Loss [106, 400](epoch, minibatch):  0.6457833752036095\n",
            "Loss [106, 500](epoch, minibatch):  0.6625661796331406\n",
            "Loss [106, 600](epoch, minibatch):  0.683230120241642\n",
            "Accuracy test images:  76.38000000000001 %\n",
            "Loss [107, 100](epoch, minibatch):  0.6337535008788109\n",
            "Loss [107, 200](epoch, minibatch):  0.6490358597040177\n",
            "Loss [107, 300](epoch, minibatch):  0.6495698353648186\n",
            "Loss [107, 400](epoch, minibatch):  0.6490590885281563\n",
            "Loss [107, 500](epoch, minibatch):  0.6597529083490372\n",
            "Loss [107, 600](epoch, minibatch):  0.6953775599598885\n",
            "Accuracy test images:  77.23 %\n",
            "Loss [108, 100](epoch, minibatch):  0.6320810225605965\n",
            "Loss [108, 200](epoch, minibatch):  0.6807432553172111\n",
            "Loss [108, 300](epoch, minibatch):  0.6341088086366653\n",
            "Loss [108, 400](epoch, minibatch):  0.6754172784090042\n",
            "Loss [108, 500](epoch, minibatch):  0.6815527951717377\n",
            "Loss [108, 600](epoch, minibatch):  0.6559397524595261\n",
            "Accuracy test images:  76.16000000000001 %\n",
            "Loss [109, 100](epoch, minibatch):  0.666761402785778\n",
            "Loss [109, 200](epoch, minibatch):  0.6528525778651237\n",
            "Loss [109, 300](epoch, minibatch):  0.6511898952722549\n",
            "Loss [109, 400](epoch, minibatch):  0.6518911018967628\n",
            "Loss [109, 500](epoch, minibatch):  0.6623157939314842\n",
            "Loss [109, 600](epoch, minibatch):  0.6629870173335075\n",
            "Accuracy test images:  77.16 %\n",
            "Loss [110, 100](epoch, minibatch):  0.6522975063323975\n",
            "Loss [110, 200](epoch, minibatch):  0.645685533285141\n",
            "Loss [110, 300](epoch, minibatch):  0.659597840309143\n",
            "Loss [110, 400](epoch, minibatch):  0.6587601631879807\n",
            "Loss [110, 500](epoch, minibatch):  0.6578714644908905\n",
            "Loss [110, 600](epoch, minibatch):  0.6590210002660751\n",
            "Accuracy test images:  76.68 %\n",
            "Loss [111, 100](epoch, minibatch):  0.6514499843120575\n",
            "Loss [111, 200](epoch, minibatch):  0.653516828417778\n",
            "Loss [111, 300](epoch, minibatch):  0.6704932969808578\n",
            "Loss [111, 400](epoch, minibatch):  0.6455686405301094\n",
            "Loss [111, 500](epoch, minibatch):  0.6423793563246727\n",
            "Loss [111, 600](epoch, minibatch):  0.6418396472930908\n",
            "Accuracy test images:  76.99000000000001 %\n",
            "Loss [112, 100](epoch, minibatch):  0.6519785514473915\n",
            "Loss [112, 200](epoch, minibatch):  0.623878156542778\n",
            "Loss [112, 300](epoch, minibatch):  0.6498669031262397\n",
            "Loss [112, 400](epoch, minibatch):  0.6616424852609635\n",
            "Loss [112, 500](epoch, minibatch):  0.6450395810604096\n",
            "Loss [112, 600](epoch, minibatch):  0.6450090953707694\n",
            "Accuracy test images:  76.42999999999999 %\n",
            "Loss [113, 100](epoch, minibatch):  0.6285786280035972\n",
            "Loss [113, 200](epoch, minibatch):  0.643811683356762\n",
            "Loss [113, 300](epoch, minibatch):  0.6319819101691246\n",
            "Loss [113, 400](epoch, minibatch):  0.6489747768640518\n",
            "Loss [113, 500](epoch, minibatch):  0.6439351296424866\n",
            "Loss [113, 600](epoch, minibatch):  0.6690924951434135\n",
            "Accuracy test images:  77.84 %\n",
            "Loss [114, 100](epoch, minibatch):  0.6113137117028237\n",
            "Loss [114, 200](epoch, minibatch):  0.6307944455742835\n",
            "Loss [114, 300](epoch, minibatch):  0.6353335982561111\n",
            "Loss [114, 400](epoch, minibatch):  0.6686398047208786\n",
            "Loss [114, 500](epoch, minibatch):  0.6470060792565345\n",
            "Loss [114, 600](epoch, minibatch):  0.6688940361142158\n",
            "Accuracy test images:  76.91 %\n",
            "Loss [115, 100](epoch, minibatch):  0.6305548924207688\n",
            "Loss [115, 200](epoch, minibatch):  0.6276712048053742\n",
            "Loss [115, 300](epoch, minibatch):  0.6374665942788124\n",
            "Loss [115, 400](epoch, minibatch):  0.6475782960653305\n",
            "Loss [115, 500](epoch, minibatch):  0.653173403441906\n",
            "Loss [115, 600](epoch, minibatch):  0.664950832426548\n",
            "Accuracy test images:  77.01 %\n",
            "Loss [116, 100](epoch, minibatch):  0.6291768825054169\n",
            "Loss [116, 200](epoch, minibatch):  0.6524956834316253\n",
            "Loss [116, 300](epoch, minibatch):  0.6279286646842956\n",
            "Loss [116, 400](epoch, minibatch):  0.6336506074666977\n",
            "Loss [116, 500](epoch, minibatch):  0.6683382043242454\n",
            "Loss [116, 600](epoch, minibatch):  0.6646085813641548\n",
            "Accuracy test images:  76.1 %\n",
            "Loss [117, 100](epoch, minibatch):  0.6411159512400627\n",
            "Loss [117, 200](epoch, minibatch):  0.6364211642742157\n",
            "Loss [117, 300](epoch, minibatch):  0.6571578392386437\n",
            "Loss [117, 400](epoch, minibatch):  0.6546072834730148\n",
            "Loss [117, 500](epoch, minibatch):  0.6338637980818749\n",
            "Loss [117, 600](epoch, minibatch):  0.6689173242449761\n",
            "Accuracy test images:  76.53999999999999 %\n",
            "Loss [118, 100](epoch, minibatch):  0.6718835678696632\n",
            "Loss [118, 200](epoch, minibatch):  0.6465387454628945\n",
            "Loss [118, 300](epoch, minibatch):  0.6448061487078667\n",
            "Loss [118, 400](epoch, minibatch):  0.6531067571043968\n",
            "Loss [118, 500](epoch, minibatch):  0.634487920999527\n",
            "Loss [118, 600](epoch, minibatch):  0.6385082677006721\n",
            "Accuracy test images:  77.92 %\n",
            "Loss [119, 100](epoch, minibatch):  0.6337934824824333\n",
            "Loss [119, 200](epoch, minibatch):  0.6461253589391709\n",
            "Loss [119, 300](epoch, minibatch):  0.643112864792347\n",
            "Loss [119, 400](epoch, minibatch):  0.6479433578252792\n",
            "Loss [119, 500](epoch, minibatch):  0.660291768014431\n",
            "Loss [119, 600](epoch, minibatch):  0.6476201593875885\n",
            "Accuracy test images:  76.66 %\n",
            "Loss [120, 100](epoch, minibatch):  0.6538927766680718\n",
            "Loss [120, 200](epoch, minibatch):  0.6327887472510337\n",
            "Loss [120, 300](epoch, minibatch):  0.6435779237747192\n",
            "Loss [120, 400](epoch, minibatch):  0.6435395106673241\n",
            "Loss [120, 500](epoch, minibatch):  0.6482649618387222\n",
            "Loss [120, 600](epoch, minibatch):  0.633761876821518\n",
            "Accuracy test images:  76.64 %\n",
            "Loss [121, 100](epoch, minibatch):  0.5723211506009102\n",
            "Loss [121, 200](epoch, minibatch):  0.47263843908905984\n",
            "Loss [121, 300](epoch, minibatch):  0.4504543067514896\n",
            "Loss [121, 400](epoch, minibatch):  0.46392848014831545\n",
            "Loss [121, 500](epoch, minibatch):  0.45124115407466886\n",
            "Loss [121, 600](epoch, minibatch):  0.4338889643549919\n",
            "Accuracy test images:  81.78 %\n",
            "Loss [122, 100](epoch, minibatch):  0.4126399421691895\n",
            "Loss [122, 200](epoch, minibatch):  0.4188620072603226\n",
            "Loss [122, 300](epoch, minibatch):  0.3839227442443371\n",
            "Loss [122, 400](epoch, minibatch):  0.4174576270580292\n",
            "Loss [122, 500](epoch, minibatch):  0.4066368918120861\n",
            "Loss [122, 600](epoch, minibatch):  0.40172934710979463\n",
            "Accuracy test images:  82.06 %\n",
            "Loss [123, 100](epoch, minibatch):  0.3747632037103176\n",
            "Loss [123, 200](epoch, minibatch):  0.37845593482255935\n",
            "Loss [123, 300](epoch, minibatch):  0.38979998156428336\n",
            "Loss [123, 400](epoch, minibatch):  0.38816134944558145\n",
            "Loss [123, 500](epoch, minibatch):  0.3944564898312092\n",
            "Loss [123, 600](epoch, minibatch):  0.3613352996855974\n",
            "Accuracy test images:  82.52000000000001 %\n",
            "Loss [124, 100](epoch, minibatch):  0.3828940851986408\n",
            "Loss [124, 200](epoch, minibatch):  0.3818816293776035\n",
            "Loss [124, 300](epoch, minibatch):  0.3719308960437775\n",
            "Loss [124, 400](epoch, minibatch):  0.35587621554732324\n",
            "Loss [124, 500](epoch, minibatch):  0.367839644998312\n",
            "Loss [124, 600](epoch, minibatch):  0.3585409760475159\n",
            "Accuracy test images:  82.47 %\n",
            "Loss [125, 100](epoch, minibatch):  0.3567617632448673\n",
            "Loss [125, 200](epoch, minibatch):  0.35048261284828186\n",
            "Loss [125, 300](epoch, minibatch):  0.36369132399559023\n",
            "Loss [125, 400](epoch, minibatch):  0.3513241316378117\n",
            "Loss [125, 500](epoch, minibatch):  0.33709555625915527\n",
            "Loss [125, 600](epoch, minibatch):  0.35591003209352495\n",
            "Accuracy test images:  82.84 %\n",
            "Loss [126, 100](epoch, minibatch):  0.3661605550348759\n",
            "Loss [126, 200](epoch, minibatch):  0.36045691549777986\n",
            "Loss [126, 300](epoch, minibatch):  0.32689414769411085\n",
            "Loss [126, 400](epoch, minibatch):  0.3437708032876253\n",
            "Loss [126, 500](epoch, minibatch):  0.3427955724298954\n",
            "Loss [126, 600](epoch, minibatch):  0.34450833275914194\n",
            "Accuracy test images:  82.67 %\n",
            "Loss [127, 100](epoch, minibatch):  0.3255761037766933\n",
            "Loss [127, 200](epoch, minibatch):  0.3328064113855362\n",
            "Loss [127, 300](epoch, minibatch):  0.34221856683492663\n",
            "Loss [127, 400](epoch, minibatch):  0.3429047901928425\n",
            "Loss [127, 500](epoch, minibatch):  0.3392190247774124\n",
            "Loss [127, 600](epoch, minibatch):  0.32590507313609124\n",
            "Accuracy test images:  83.07 %\n",
            "Loss [128, 100](epoch, minibatch):  0.33611917108297346\n",
            "Loss [128, 200](epoch, minibatch):  0.3239034008234739\n",
            "Loss [128, 300](epoch, minibatch):  0.33587136030197146\n",
            "Loss [128, 400](epoch, minibatch):  0.3203109849244356\n",
            "Loss [128, 500](epoch, minibatch):  0.3378587281703949\n",
            "Loss [128, 600](epoch, minibatch):  0.3178279262036085\n",
            "Accuracy test images:  82.82000000000001 %\n",
            "Loss [129, 100](epoch, minibatch):  0.3061416880041361\n",
            "Loss [129, 200](epoch, minibatch):  0.3287862129509449\n",
            "Loss [129, 300](epoch, minibatch):  0.30979194059967996\n",
            "Loss [129, 400](epoch, minibatch):  0.32308668226003645\n",
            "Loss [129, 500](epoch, minibatch):  0.3254741513729095\n",
            "Loss [129, 600](epoch, minibatch):  0.30447943426668644\n",
            "Accuracy test images:  83.46000000000001 %\n",
            "Loss [130, 100](epoch, minibatch):  0.3292741110920906\n",
            "Loss [130, 200](epoch, minibatch):  0.3107504740357399\n",
            "Loss [130, 300](epoch, minibatch):  0.3044018442183733\n",
            "Loss [130, 400](epoch, minibatch):  0.3195908297598362\n",
            "Loss [130, 500](epoch, minibatch):  0.324186585098505\n",
            "Loss [130, 600](epoch, minibatch):  0.31316126048564913\n",
            "Accuracy test images:  83.19 %\n",
            "Loss [131, 100](epoch, minibatch):  0.3020101998001337\n",
            "Loss [131, 200](epoch, minibatch):  0.2996665254235268\n",
            "Loss [131, 300](epoch, minibatch):  0.2874419810622931\n",
            "Loss [131, 400](epoch, minibatch):  0.32564396075904367\n",
            "Loss [131, 500](epoch, minibatch):  0.28913516908884046\n",
            "Loss [131, 600](epoch, minibatch):  0.31155920326709746\n",
            "Accuracy test images:  83.78999999999999 %\n",
            "Loss [132, 100](epoch, minibatch):  0.30159028962254525\n",
            "Loss [132, 200](epoch, minibatch):  0.30820960834622385\n",
            "Loss [132, 300](epoch, minibatch):  0.30691359266638757\n",
            "Loss [132, 400](epoch, minibatch):  0.2929637335240841\n",
            "Loss [132, 500](epoch, minibatch):  0.3173907417058945\n",
            "Loss [132, 600](epoch, minibatch):  0.30464731618762014\n",
            "Accuracy test images:  83.45 %\n",
            "Loss [133, 100](epoch, minibatch):  0.2917814563959837\n",
            "Loss [133, 200](epoch, minibatch):  0.2880900410562754\n",
            "Loss [133, 300](epoch, minibatch):  0.29062516301870345\n",
            "Loss [133, 400](epoch, minibatch):  0.3084022454917431\n",
            "Loss [133, 500](epoch, minibatch):  0.2956536296010017\n",
            "Loss [133, 600](epoch, minibatch):  0.2951034762710333\n",
            "Accuracy test images:  83.6 %\n",
            "Loss [134, 100](epoch, minibatch):  0.2868337827920914\n",
            "Loss [134, 200](epoch, minibatch):  0.29252268731594083\n",
            "Loss [134, 300](epoch, minibatch):  0.26793994635343554\n",
            "Loss [134, 400](epoch, minibatch):  0.2859079483151436\n",
            "Loss [134, 500](epoch, minibatch):  0.296741052120924\n",
            "Loss [134, 600](epoch, minibatch):  0.30595153898000715\n",
            "Accuracy test images:  83.66 %\n",
            "Loss [135, 100](epoch, minibatch):  0.2791289372742176\n",
            "Loss [135, 200](epoch, minibatch):  0.2828471030294895\n",
            "Loss [135, 300](epoch, minibatch):  0.2914863599836826\n",
            "Loss [135, 400](epoch, minibatch):  0.2860232474654913\n",
            "Loss [135, 500](epoch, minibatch):  0.29427131567150355\n",
            "Loss [135, 600](epoch, minibatch):  0.2806130426377058\n",
            "Accuracy test images:  83.72 %\n",
            "Loss [136, 100](epoch, minibatch):  0.2642299658805132\n",
            "Loss [136, 200](epoch, minibatch):  0.2669552120566368\n",
            "Loss [136, 300](epoch, minibatch):  0.2743754840642214\n",
            "Loss [136, 400](epoch, minibatch):  0.280454356148839\n",
            "Loss [136, 500](epoch, minibatch):  0.2638020943850279\n",
            "Loss [136, 600](epoch, minibatch):  0.27646356023848057\n",
            "Accuracy test images:  83.87 %\n",
            "Loss [137, 100](epoch, minibatch):  0.2671366258710623\n",
            "Loss [137, 200](epoch, minibatch):  0.2542371901124716\n",
            "Loss [137, 300](epoch, minibatch):  0.28450891476124524\n",
            "Loss [137, 400](epoch, minibatch):  0.26941483445465564\n",
            "Loss [137, 500](epoch, minibatch):  0.27012138336896896\n",
            "Loss [137, 600](epoch, minibatch):  0.27537343703210354\n",
            "Accuracy test images:  83.42 %\n",
            "Loss [138, 100](epoch, minibatch):  0.2674685826152563\n",
            "Loss [138, 200](epoch, minibatch):  0.2746009678393602\n",
            "Loss [138, 300](epoch, minibatch):  0.28101222530007364\n",
            "Loss [138, 400](epoch, minibatch):  0.2731097044050694\n",
            "Loss [138, 500](epoch, minibatch):  0.2849827103316784\n",
            "Loss [138, 600](epoch, minibatch):  0.2741920797526836\n",
            "Accuracy test images:  83.59 %\n",
            "Loss [139, 100](epoch, minibatch):  0.26893217526376245\n",
            "Loss [139, 200](epoch, minibatch):  0.2659225832670927\n",
            "Loss [139, 300](epoch, minibatch):  0.27207914598286154\n",
            "Loss [139, 400](epoch, minibatch):  0.24238817200064658\n",
            "Loss [139, 500](epoch, minibatch):  0.2799548950046301\n",
            "Loss [139, 600](epoch, minibatch):  0.25981837436556815\n",
            "Accuracy test images:  83.43 %\n",
            "Loss [140, 100](epoch, minibatch):  0.24635728046298028\n",
            "Loss [140, 200](epoch, minibatch):  0.2619915893673897\n",
            "Loss [140, 300](epoch, minibatch):  0.26579561524093154\n",
            "Loss [140, 400](epoch, minibatch):  0.2762858149409294\n",
            "Loss [140, 500](epoch, minibatch):  0.2710850501060486\n",
            "Loss [140, 600](epoch, minibatch):  0.2740406496077776\n",
            "Accuracy test images:  83.12 %\n",
            "Loss [141, 100](epoch, minibatch):  0.2595442476123571\n",
            "Loss [141, 200](epoch, minibatch):  0.24062669336795806\n",
            "Loss [141, 300](epoch, minibatch):  0.2415741328150034\n",
            "Loss [141, 400](epoch, minibatch):  0.2638188529759645\n",
            "Loss [141, 500](epoch, minibatch):  0.2488201268017292\n",
            "Loss [141, 600](epoch, minibatch):  0.25830834679305553\n",
            "Accuracy test images:  83.22 %\n",
            "Loss [142, 100](epoch, minibatch):  0.24853179723024368\n",
            "Loss [142, 200](epoch, minibatch):  0.24845639050006865\n",
            "Loss [142, 300](epoch, minibatch):  0.26260203756392003\n",
            "Loss [142, 400](epoch, minibatch):  0.2650428181886673\n",
            "Loss [142, 500](epoch, minibatch):  0.2673181952536106\n",
            "Loss [142, 600](epoch, minibatch):  0.2537583173066378\n",
            "Accuracy test images:  82.76 %\n",
            "Loss [143, 100](epoch, minibatch):  0.25253493428230284\n",
            "Loss [143, 200](epoch, minibatch):  0.2547678584977984\n",
            "Loss [143, 300](epoch, minibatch):  0.2514620076864958\n",
            "Loss [143, 400](epoch, minibatch):  0.25098698630928995\n",
            "Loss [143, 500](epoch, minibatch):  0.25749991908669473\n",
            "Loss [143, 600](epoch, minibatch):  0.2610242767632008\n",
            "Accuracy test images:  83.28999999999999 %\n",
            "Loss [144, 100](epoch, minibatch):  0.24462262116372585\n",
            "Loss [144, 200](epoch, minibatch):  0.24131646566092968\n",
            "Loss [144, 300](epoch, minibatch):  0.2591485340148211\n",
            "Loss [144, 400](epoch, minibatch):  0.2525018586218357\n",
            "Loss [144, 500](epoch, minibatch):  0.2569962303340435\n",
            "Loss [144, 600](epoch, minibatch):  0.2540890695899725\n",
            "Accuracy test images:  83.52000000000001 %\n",
            "Loss [145, 100](epoch, minibatch):  0.2509308009594679\n",
            "Loss [145, 200](epoch, minibatch):  0.23859706632792949\n",
            "Loss [145, 300](epoch, minibatch):  0.2479583228379488\n",
            "Loss [145, 400](epoch, minibatch):  0.23567374497652055\n",
            "Loss [145, 500](epoch, minibatch):  0.24462722800672054\n",
            "Loss [145, 600](epoch, minibatch):  0.25716975376009943\n",
            "Accuracy test images:  82.88 %\n",
            "Loss [146, 100](epoch, minibatch):  0.22044028349220754\n",
            "Loss [146, 200](epoch, minibatch):  0.2338844595104456\n",
            "Loss [146, 300](epoch, minibatch):  0.2546519237756729\n",
            "Loss [146, 400](epoch, minibatch):  0.2494160008430481\n",
            "Loss [146, 500](epoch, minibatch):  0.24563230656087398\n",
            "Loss [146, 600](epoch, minibatch):  0.24362351395189763\n",
            "Accuracy test images:  83.33 %\n",
            "Loss [147, 100](epoch, minibatch):  0.24254041254520417\n",
            "Loss [147, 200](epoch, minibatch):  0.22740713633596898\n",
            "Loss [147, 300](epoch, minibatch):  0.2563661652803421\n",
            "Loss [147, 400](epoch, minibatch):  0.23173035271465778\n",
            "Loss [147, 500](epoch, minibatch):  0.23440704360604286\n",
            "Loss [147, 600](epoch, minibatch):  0.23814608655869962\n",
            "Accuracy test images:  83.2 %\n",
            "Loss [148, 100](epoch, minibatch):  0.23710481725633145\n",
            "Loss [148, 200](epoch, minibatch):  0.23209843777120112\n",
            "Loss [148, 300](epoch, minibatch):  0.24462257809937\n",
            "Loss [148, 400](epoch, minibatch):  0.24985205851495265\n",
            "Loss [148, 500](epoch, minibatch):  0.22971802994608878\n",
            "Loss [148, 600](epoch, minibatch):  0.2418012446910143\n",
            "Accuracy test images:  83.15 %\n",
            "Loss [149, 100](epoch, minibatch):  0.2303189931064844\n",
            "Loss [149, 200](epoch, minibatch):  0.2140104541182518\n",
            "Loss [149, 300](epoch, minibatch):  0.23281274698674678\n",
            "Loss [149, 400](epoch, minibatch):  0.22999603062868118\n",
            "Loss [149, 500](epoch, minibatch):  0.24447088569402695\n",
            "Loss [149, 600](epoch, minibatch):  0.23595015436410904\n",
            "Accuracy test images:  82.80999999999999 %\n",
            "Loss [150, 100](epoch, minibatch):  0.22512447610497474\n",
            "Loss [150, 200](epoch, minibatch):  0.2153535472601652\n",
            "Loss [150, 300](epoch, minibatch):  0.22351102195680142\n",
            "Loss [150, 400](epoch, minibatch):  0.230185968503356\n",
            "Loss [150, 500](epoch, minibatch):  0.2364843924343586\n",
            "Loss [150, 600](epoch, minibatch):  0.23684908650815487\n",
            "Accuracy test images:  83.48 %\n",
            "Loss [151, 100](epoch, minibatch):  0.22723114676773548\n",
            "Loss [151, 200](epoch, minibatch):  0.21453362658619882\n",
            "Loss [151, 300](epoch, minibatch):  0.23016476429998875\n",
            "Loss [151, 400](epoch, minibatch):  0.23211214892566204\n",
            "Loss [151, 500](epoch, minibatch):  0.22876285366714\n",
            "Loss [151, 600](epoch, minibatch):  0.24598293825984002\n",
            "Accuracy test images:  83.25 %\n",
            "Loss [152, 100](epoch, minibatch):  0.21791194595396518\n",
            "Loss [152, 200](epoch, minibatch):  0.21030028209090232\n",
            "Loss [152, 300](epoch, minibatch):  0.2199661785364151\n",
            "Loss [152, 400](epoch, minibatch):  0.22685106832534074\n",
            "Loss [152, 500](epoch, minibatch):  0.24025510631501676\n",
            "Loss [152, 600](epoch, minibatch):  0.2377604293078184\n",
            "Accuracy test images:  83.73 %\n",
            "Loss [153, 100](epoch, minibatch):  0.2230416451394558\n",
            "Loss [153, 200](epoch, minibatch):  0.2232756085693836\n",
            "Loss [153, 300](epoch, minibatch):  0.22438136521726848\n",
            "Loss [153, 400](epoch, minibatch):  0.22109826900064944\n",
            "Loss [153, 500](epoch, minibatch):  0.21674708507955073\n",
            "Loss [153, 600](epoch, minibatch):  0.22424458011984824\n",
            "Accuracy test images:  83.25 %\n",
            "Loss [154, 100](epoch, minibatch):  0.2172863359004259\n",
            "Loss [154, 200](epoch, minibatch):  0.21613829087466002\n",
            "Loss [154, 300](epoch, minibatch):  0.23012200713157654\n",
            "Loss [154, 400](epoch, minibatch):  0.21985031045973302\n",
            "Loss [154, 500](epoch, minibatch):  0.21528898924589157\n",
            "Loss [154, 600](epoch, minibatch):  0.23885588862001897\n",
            "Accuracy test images:  83.56 %\n",
            "Loss [155, 100](epoch, minibatch):  0.21267652414739133\n",
            "Loss [155, 200](epoch, minibatch):  0.2185303995013237\n",
            "Loss [155, 300](epoch, minibatch):  0.21054073490202427\n",
            "Loss [155, 400](epoch, minibatch):  0.21955369852483272\n",
            "Loss [155, 500](epoch, minibatch):  0.22566204115748406\n",
            "Loss [155, 600](epoch, minibatch):  0.23079698838293553\n",
            "Accuracy test images:  83.50999999999999 %\n",
            "Loss [156, 100](epoch, minibatch):  0.21329405687749386\n",
            "Loss [156, 200](epoch, minibatch):  0.21314599305391313\n",
            "Loss [156, 300](epoch, minibatch):  0.21716293416917323\n",
            "Loss [156, 400](epoch, minibatch):  0.21588748946785927\n",
            "Loss [156, 500](epoch, minibatch):  0.21327627249062062\n",
            "Loss [156, 600](epoch, minibatch):  0.23412034813314675\n",
            "Accuracy test images:  82.89999999999999 %\n",
            "Loss [157, 100](epoch, minibatch):  0.21439029835164547\n",
            "Loss [157, 200](epoch, minibatch):  0.21938106641173363\n",
            "Loss [157, 300](epoch, minibatch):  0.21029535055160523\n",
            "Loss [157, 400](epoch, minibatch):  0.2336525743454695\n",
            "Loss [157, 500](epoch, minibatch):  0.22090998943895102\n",
            "Loss [157, 600](epoch, minibatch):  0.20531560048460962\n",
            "Accuracy test images:  83.19 %\n",
            "Loss [158, 100](epoch, minibatch):  0.20436119757592677\n",
            "Loss [158, 200](epoch, minibatch):  0.2026764824613929\n",
            "Loss [158, 300](epoch, minibatch):  0.2256365218013525\n",
            "Loss [158, 400](epoch, minibatch):  0.21214736081659794\n",
            "Loss [158, 500](epoch, minibatch):  0.21162651993334294\n",
            "Loss [158, 600](epoch, minibatch):  0.21281761035323143\n",
            "Accuracy test images:  82.78 %\n",
            "Loss [159, 100](epoch, minibatch):  0.21310846572741865\n",
            "Loss [159, 200](epoch, minibatch):  0.21825637303292753\n",
            "Loss [159, 300](epoch, minibatch):  0.20210730478167535\n",
            "Loss [159, 400](epoch, minibatch):  0.21907545000314713\n",
            "Loss [159, 500](epoch, minibatch):  0.20007217179983855\n",
            "Loss [159, 600](epoch, minibatch):  0.2219242339581251\n",
            "Accuracy test images:  83.1 %\n",
            "Loss [160, 100](epoch, minibatch):  0.2108305863291025\n",
            "Loss [160, 200](epoch, minibatch):  0.21533813320100306\n",
            "Loss [160, 300](epoch, minibatch):  0.20003526322543622\n",
            "Loss [160, 400](epoch, minibatch):  0.20962199084460736\n",
            "Loss [160, 500](epoch, minibatch):  0.21909241653978825\n",
            "Loss [160, 600](epoch, minibatch):  0.20767777536064386\n",
            "Accuracy test images:  83.39999999999999 %\n",
            "Loss [161, 100](epoch, minibatch):  0.21248455256223678\n",
            "Loss [161, 200](epoch, minibatch):  0.21777221195399762\n",
            "Loss [161, 300](epoch, minibatch):  0.21951110925525427\n",
            "Loss [161, 400](epoch, minibatch):  0.2020322981849313\n",
            "Loss [161, 500](epoch, minibatch):  0.22061394065618514\n",
            "Loss [161, 600](epoch, minibatch):  0.2204104944318533\n",
            "Accuracy test images:  83.14 %\n",
            "Loss [162, 100](epoch, minibatch):  0.19948669452220202\n",
            "Loss [162, 200](epoch, minibatch):  0.21667987160384655\n",
            "Loss [162, 300](epoch, minibatch):  0.20871405735611914\n",
            "Loss [162, 400](epoch, minibatch):  0.21576198112219572\n",
            "Loss [162, 500](epoch, minibatch):  0.20665432341396808\n",
            "Loss [162, 600](epoch, minibatch):  0.20676178105175494\n",
            "Accuracy test images:  82.6 %\n",
            "Loss [163, 100](epoch, minibatch):  0.20379415687173605\n",
            "Loss [163, 200](epoch, minibatch):  0.21750561460852624\n",
            "Loss [163, 300](epoch, minibatch):  0.21507708713412285\n",
            "Loss [163, 400](epoch, minibatch):  0.19874684162437917\n",
            "Loss [163, 500](epoch, minibatch):  0.20013728886842727\n",
            "Loss [163, 600](epoch, minibatch):  0.20015733420848847\n",
            "Accuracy test images:  82.53 %\n",
            "Loss [164, 100](epoch, minibatch):  0.19696625888347627\n",
            "Loss [164, 200](epoch, minibatch):  0.21096840098500252\n",
            "Loss [164, 300](epoch, minibatch):  0.19324762053787709\n",
            "Loss [164, 400](epoch, minibatch):  0.21037783347070216\n",
            "Loss [164, 500](epoch, minibatch):  0.20718956165015698\n",
            "Loss [164, 600](epoch, minibatch):  0.20912830732762813\n",
            "Accuracy test images:  83.17 %\n",
            "Loss [165, 100](epoch, minibatch):  0.18601735029369593\n",
            "Loss [165, 200](epoch, minibatch):  0.20128605840727687\n",
            "Loss [165, 300](epoch, minibatch):  0.2042451573908329\n",
            "Loss [165, 400](epoch, minibatch):  0.21670691177248955\n",
            "Loss [165, 500](epoch, minibatch):  0.2092088581621647\n",
            "Loss [165, 600](epoch, minibatch):  0.2153469893336296\n",
            "Accuracy test images:  83.03 %\n",
            "Loss [166, 100](epoch, minibatch):  0.18901897087693215\n",
            "Loss [166, 200](epoch, minibatch):  0.19480061009526253\n",
            "Loss [166, 300](epoch, minibatch):  0.20015034545212984\n",
            "Loss [166, 400](epoch, minibatch):  0.20509672183543443\n",
            "Loss [166, 500](epoch, minibatch):  0.2107919304072857\n",
            "Loss [166, 600](epoch, minibatch):  0.21964261054992676\n",
            "Accuracy test images:  82.84 %\n",
            "Loss [167, 100](epoch, minibatch):  0.1938946582004428\n",
            "Loss [167, 200](epoch, minibatch):  0.18476531762629747\n",
            "Loss [167, 300](epoch, minibatch):  0.19347178023308514\n",
            "Loss [167, 400](epoch, minibatch):  0.20173099219799043\n",
            "Loss [167, 500](epoch, minibatch):  0.22371928095817567\n",
            "Loss [167, 600](epoch, minibatch):  0.2247107047587633\n",
            "Accuracy test images:  82.92 %\n",
            "Loss [168, 100](epoch, minibatch):  0.19346357852220536\n",
            "Loss [168, 200](epoch, minibatch):  0.18288938190788032\n",
            "Loss [168, 300](epoch, minibatch):  0.19219873361289502\n",
            "Loss [168, 400](epoch, minibatch):  0.21018314052373172\n",
            "Loss [168, 500](epoch, minibatch):  0.1999381808191538\n",
            "Loss [168, 600](epoch, minibatch):  0.21348068095743655\n",
            "Accuracy test images:  82.27 %\n",
            "Loss [169, 100](epoch, minibatch):  0.1839206064119935\n",
            "Loss [169, 200](epoch, minibatch):  0.19320991177111865\n",
            "Loss [169, 300](epoch, minibatch):  0.20528827734291555\n",
            "Loss [169, 400](epoch, minibatch):  0.20479461848735808\n",
            "Loss [169, 500](epoch, minibatch):  0.20379937302321197\n",
            "Loss [169, 600](epoch, minibatch):  0.20069593604654073\n",
            "Accuracy test images:  83.0 %\n",
            "Loss [170, 100](epoch, minibatch):  0.18552480686455966\n",
            "Loss [170, 200](epoch, minibatch):  0.1869000731408596\n",
            "Loss [170, 300](epoch, minibatch):  0.20858293302357198\n",
            "Loss [170, 400](epoch, minibatch):  0.20211992032825946\n",
            "Loss [170, 500](epoch, minibatch):  0.19926838453859091\n",
            "Loss [170, 600](epoch, minibatch):  0.21018971305340528\n",
            "Accuracy test images:  82.69999999999999 %\n",
            "Loss [171, 100](epoch, minibatch):  0.18514114297926426\n",
            "Loss [171, 200](epoch, minibatch):  0.19095691189169883\n",
            "Loss [171, 300](epoch, minibatch):  0.2071928907185793\n",
            "Loss [171, 400](epoch, minibatch):  0.19986236818134784\n",
            "Loss [171, 500](epoch, minibatch):  0.192636074796319\n",
            "Loss [171, 600](epoch, minibatch):  0.1977673691138625\n",
            "Accuracy test images:  82.89 %\n",
            "Loss [172, 100](epoch, minibatch):  0.1887605544179678\n",
            "Loss [172, 200](epoch, minibatch):  0.1967820278555155\n",
            "Loss [172, 300](epoch, minibatch):  0.20446396119892596\n",
            "Loss [172, 400](epoch, minibatch):  0.1965174600481987\n",
            "Loss [172, 500](epoch, minibatch):  0.1856137603521347\n",
            "Loss [172, 600](epoch, minibatch):  0.20611960247159003\n",
            "Accuracy test images:  83.36 %\n",
            "Loss [173, 100](epoch, minibatch):  0.1895340371131897\n",
            "Loss [173, 200](epoch, minibatch):  0.1859133454784751\n",
            "Loss [173, 300](epoch, minibatch):  0.19744614757597445\n",
            "Loss [173, 400](epoch, minibatch):  0.1988351357728243\n",
            "Loss [173, 500](epoch, minibatch):  0.2008717379719019\n",
            "Loss [173, 600](epoch, minibatch):  0.2046460223197937\n",
            "Accuracy test images:  82.87 %\n",
            "Loss [174, 100](epoch, minibatch):  0.18842544008046389\n",
            "Loss [174, 200](epoch, minibatch):  0.20345643781125544\n",
            "Loss [174, 300](epoch, minibatch):  0.19224561162292958\n",
            "Loss [174, 400](epoch, minibatch):  0.19785002566874027\n",
            "Loss [174, 500](epoch, minibatch):  0.19756477892398835\n",
            "Loss [174, 600](epoch, minibatch):  0.19255039904266597\n",
            "Accuracy test images:  82.78999999999999 %\n",
            "Loss [175, 100](epoch, minibatch):  0.19611008517444134\n",
            "Loss [175, 200](epoch, minibatch):  0.1813018150627613\n",
            "Loss [175, 300](epoch, minibatch):  0.18901799999177457\n",
            "Loss [175, 400](epoch, minibatch):  0.18800867471843957\n",
            "Loss [175, 500](epoch, minibatch):  0.1901912947371602\n",
            "Loss [175, 600](epoch, minibatch):  0.20159421931952237\n",
            "Accuracy test images:  82.67999999999999 %\n",
            "Loss [176, 100](epoch, minibatch):  0.18795213244855405\n",
            "Loss [176, 200](epoch, minibatch):  0.18339040126651526\n",
            "Loss [176, 300](epoch, minibatch):  0.1881686975248158\n",
            "Loss [176, 400](epoch, minibatch):  0.19153344132006167\n",
            "Loss [176, 500](epoch, minibatch):  0.1926221877336502\n",
            "Loss [176, 600](epoch, minibatch):  0.20644702460616826\n",
            "Accuracy test images:  82.16 %\n",
            "Loss [177, 100](epoch, minibatch):  0.18938508160412312\n",
            "Loss [177, 200](epoch, minibatch):  0.19272994350641967\n",
            "Loss [177, 300](epoch, minibatch):  0.1926826175302267\n",
            "Loss [177, 400](epoch, minibatch):  0.1908588683605194\n",
            "Loss [177, 500](epoch, minibatch):  0.20213786602020264\n",
            "Loss [177, 600](epoch, minibatch):  0.20517051860690116\n",
            "Accuracy test images:  82.67 %\n",
            "Loss [178, 100](epoch, minibatch):  0.19566064592450857\n",
            "Loss [178, 200](epoch, minibatch):  0.1819679756462574\n",
            "Loss [178, 300](epoch, minibatch):  0.18758463684469462\n",
            "Loss [178, 400](epoch, minibatch):  0.18810257870703936\n",
            "Loss [178, 500](epoch, minibatch):  0.19789616264402865\n",
            "Loss [178, 600](epoch, minibatch):  0.21128823973238467\n",
            "Accuracy test images:  82.66 %\n",
            "Loss [179, 100](epoch, minibatch):  0.19010395906865596\n",
            "Loss [179, 200](epoch, minibatch):  0.18801953569054602\n",
            "Loss [179, 300](epoch, minibatch):  0.20772844925522804\n",
            "Loss [179, 400](epoch, minibatch):  0.18650208838284016\n",
            "Loss [179, 500](epoch, minibatch):  0.19250384625047445\n",
            "Loss [179, 600](epoch, minibatch):  0.19088257625699043\n",
            "Accuracy test images:  82.69999999999999 %\n",
            "Loss [180, 100](epoch, minibatch):  0.18763090178370476\n",
            "Loss [180, 200](epoch, minibatch):  0.19209251210093498\n",
            "Loss [180, 300](epoch, minibatch):  0.19607294082641602\n",
            "Loss [180, 400](epoch, minibatch):  0.18724860981106758\n",
            "Loss [180, 500](epoch, minibatch):  0.1806867865845561\n",
            "Loss [180, 600](epoch, minibatch):  0.2058987032994628\n",
            "Accuracy test images:  82.35 %\n",
            "Loss [181, 100](epoch, minibatch):  0.1848653593659401\n",
            "Loss [181, 200](epoch, minibatch):  0.175048608481884\n",
            "Loss [181, 300](epoch, minibatch):  0.1905438882485032\n",
            "Loss [181, 400](epoch, minibatch):  0.18832068093121052\n",
            "Loss [181, 500](epoch, minibatch):  0.1981135204434395\n",
            "Loss [181, 600](epoch, minibatch):  0.20169671311974524\n",
            "Accuracy test images:  82.1 %\n",
            "Loss [182, 100](epoch, minibatch):  0.1708630045130849\n",
            "Loss [182, 200](epoch, minibatch):  0.17392825931310654\n",
            "Loss [182, 300](epoch, minibatch):  0.18380659624934195\n",
            "Loss [182, 400](epoch, minibatch):  0.2040269001200795\n",
            "Loss [182, 500](epoch, minibatch):  0.1939260672405362\n",
            "Loss [182, 600](epoch, minibatch):  0.1813222636282444\n",
            "Accuracy test images:  82.64 %\n",
            "Loss [183, 100](epoch, minibatch):  0.17573796030133962\n",
            "Loss [183, 200](epoch, minibatch):  0.17872914105653762\n",
            "Loss [183, 300](epoch, minibatch):  0.19158082600682974\n",
            "Loss [183, 400](epoch, minibatch):  0.19570126678794622\n",
            "Loss [183, 500](epoch, minibatch):  0.18335471697151662\n",
            "Loss [183, 600](epoch, minibatch):  0.20272718071937562\n",
            "Accuracy test images:  82.52000000000001 %\n",
            "Loss [184, 100](epoch, minibatch):  0.18143882237374784\n",
            "Loss [184, 200](epoch, minibatch):  0.1823134109377861\n",
            "Loss [184, 300](epoch, minibatch):  0.17852551180869342\n",
            "Loss [184, 400](epoch, minibatch):  0.16714060682803392\n",
            "Loss [184, 500](epoch, minibatch):  0.19193871267139911\n",
            "Loss [184, 600](epoch, minibatch):  0.20079299069941045\n",
            "Accuracy test images:  82.71 %\n",
            "Loss [185, 100](epoch, minibatch):  0.17004399167373777\n",
            "Loss [185, 200](epoch, minibatch):  0.189711535833776\n",
            "Loss [185, 300](epoch, minibatch):  0.19200537644326687\n",
            "Loss [185, 400](epoch, minibatch):  0.19831611070781946\n",
            "Loss [185, 500](epoch, minibatch):  0.18904911067336796\n",
            "Loss [185, 600](epoch, minibatch):  0.199947926774621\n",
            "Accuracy test images:  82.62 %\n",
            "Loss [186, 100](epoch, minibatch):  0.17095756251364946\n",
            "Loss [186, 200](epoch, minibatch):  0.18976833425462247\n",
            "Loss [186, 300](epoch, minibatch):  0.17882709980010986\n",
            "Loss [186, 400](epoch, minibatch):  0.1936375166848302\n",
            "Loss [186, 500](epoch, minibatch):  0.19901069931685925\n",
            "Loss [186, 600](epoch, minibatch):  0.1891214744001627\n",
            "Accuracy test images:  82.41000000000001 %\n",
            "Loss [187, 100](epoch, minibatch):  0.16793823149055243\n",
            "Loss [187, 200](epoch, minibatch):  0.19279615193605423\n",
            "Loss [187, 300](epoch, minibatch):  0.1965646954253316\n",
            "Loss [187, 400](epoch, minibatch):  0.19264322075992824\n",
            "Loss [187, 500](epoch, minibatch):  0.17629879150539637\n",
            "Loss [187, 600](epoch, minibatch):  0.20088736537843943\n",
            "Accuracy test images:  83.39 %\n",
            "Loss [188, 100](epoch, minibatch):  0.1746243289858103\n",
            "Loss [188, 200](epoch, minibatch):  0.18848091810941697\n",
            "Loss [188, 300](epoch, minibatch):  0.1871043112501502\n",
            "Loss [188, 400](epoch, minibatch):  0.1842605647817254\n",
            "Loss [188, 500](epoch, minibatch):  0.1762815408781171\n",
            "Loss [188, 600](epoch, minibatch):  0.20701211120933294\n",
            "Accuracy test images:  82.69999999999999 %\n",
            "Loss [189, 100](epoch, minibatch):  0.1734848551824689\n",
            "Loss [189, 200](epoch, minibatch):  0.17451592590659856\n",
            "Loss [189, 300](epoch, minibatch):  0.18096004389226436\n",
            "Loss [189, 400](epoch, minibatch):  0.18639914087951184\n",
            "Loss [189, 500](epoch, minibatch):  0.18745661824941634\n",
            "Loss [189, 600](epoch, minibatch):  0.189657826423645\n",
            "Accuracy test images:  82.33 %\n",
            "Loss [190, 100](epoch, minibatch):  0.18065245099365712\n",
            "Loss [190, 200](epoch, minibatch):  0.20255589608103036\n",
            "Loss [190, 300](epoch, minibatch):  0.18366406496614218\n",
            "Loss [190, 400](epoch, minibatch):  0.1937328290194273\n",
            "Loss [190, 500](epoch, minibatch):  0.19069491997361182\n",
            "Loss [190, 600](epoch, minibatch):  0.18208450078964233\n",
            "Accuracy test images:  82.88 %\n",
            "Loss [191, 100](epoch, minibatch):  0.17369346410036088\n",
            "Loss [191, 200](epoch, minibatch):  0.1701724750548601\n",
            "Loss [191, 300](epoch, minibatch):  0.1808008795976639\n",
            "Loss [191, 400](epoch, minibatch):  0.1867099188454449\n",
            "Loss [191, 500](epoch, minibatch):  0.1803329499810934\n",
            "Loss [191, 600](epoch, minibatch):  0.17931430220603942\n",
            "Accuracy test images:  82.6 %\n",
            "Loss [192, 100](epoch, minibatch):  0.1702859378606081\n",
            "Loss [192, 200](epoch, minibatch):  0.17007306553423404\n",
            "Loss [192, 300](epoch, minibatch):  0.16743835490196943\n",
            "Loss [192, 400](epoch, minibatch):  0.1953909543156624\n",
            "Loss [192, 500](epoch, minibatch):  0.18421931974589825\n",
            "Loss [192, 600](epoch, minibatch):  0.19723100438714028\n",
            "Accuracy test images:  82.24000000000001 %\n",
            "Loss [193, 100](epoch, minibatch):  0.17703905813395976\n",
            "Loss [193, 200](epoch, minibatch):  0.1865957548096776\n",
            "Loss [193, 300](epoch, minibatch):  0.17168560165911914\n",
            "Loss [193, 400](epoch, minibatch):  0.1891106002032757\n",
            "Loss [193, 500](epoch, minibatch):  0.16803878463804722\n",
            "Loss [193, 600](epoch, minibatch):  0.17810351859778165\n",
            "Accuracy test images:  82.28999999999999 %\n",
            "Loss [194, 100](epoch, minibatch):  0.16572131395339965\n",
            "Loss [194, 200](epoch, minibatch):  0.17499383956193923\n",
            "Loss [194, 300](epoch, minibatch):  0.1829936067573726\n",
            "Loss [194, 400](epoch, minibatch):  0.17511206798255444\n",
            "Loss [194, 500](epoch, minibatch):  0.18738849312067032\n",
            "Loss [194, 600](epoch, minibatch):  0.18959043309092521\n",
            "Accuracy test images:  83.15 %\n",
            "Loss [195, 100](epoch, minibatch):  0.18015727289021016\n",
            "Loss [195, 200](epoch, minibatch):  0.181144787594676\n",
            "Loss [195, 300](epoch, minibatch):  0.18216218162328005\n",
            "Loss [195, 400](epoch, minibatch):  0.17726008545607327\n",
            "Loss [195, 500](epoch, minibatch):  0.19592540435492992\n",
            "Loss [195, 600](epoch, minibatch):  0.17542551405727863\n",
            "Accuracy test images:  82.26 %\n",
            "Loss [196, 100](epoch, minibatch):  0.1711298278719187\n",
            "Loss [196, 200](epoch, minibatch):  0.1755456158518791\n",
            "Loss [196, 300](epoch, minibatch):  0.17856914695352316\n",
            "Loss [196, 400](epoch, minibatch):  0.19335042990744114\n",
            "Loss [196, 500](epoch, minibatch):  0.1868784825503826\n",
            "Loss [196, 600](epoch, minibatch):  0.19240320283919574\n",
            "Accuracy test images:  81.87 %\n",
            "Loss [197, 100](epoch, minibatch):  0.1786852229014039\n",
            "Loss [197, 200](epoch, minibatch):  0.1827178693190217\n",
            "Loss [197, 300](epoch, minibatch):  0.17767982114106418\n",
            "Loss [197, 400](epoch, minibatch):  0.18459897860884666\n",
            "Loss [197, 500](epoch, minibatch):  0.175512833930552\n",
            "Loss [197, 600](epoch, minibatch):  0.192004032433033\n",
            "Accuracy test images:  82.85 %\n",
            "Loss [198, 100](epoch, minibatch):  0.1831823044270277\n",
            "Loss [198, 200](epoch, minibatch):  0.17153729718178512\n",
            "Loss [198, 300](epoch, minibatch):  0.18392927676439286\n",
            "Loss [198, 400](epoch, minibatch):  0.16711871556937694\n",
            "Loss [198, 500](epoch, minibatch):  0.18050197631120682\n",
            "Loss [198, 600](epoch, minibatch):  0.1912492874637246\n",
            "Accuracy test images:  82.78 %\n",
            "Loss [199, 100](epoch, minibatch):  0.1671585163474083\n",
            "Loss [199, 200](epoch, minibatch):  0.17159140687435864\n",
            "Loss [199, 300](epoch, minibatch):  0.19894312880933285\n",
            "Loss [199, 400](epoch, minibatch):  0.18151283280923963\n",
            "Loss [199, 500](epoch, minibatch):  0.18306484058499337\n",
            "Loss [199, 600](epoch, minibatch):  0.18023504173383117\n",
            "Accuracy test images:  82.99 %\n",
            "Loss [200, 100](epoch, minibatch):  0.15232353068888188\n",
            "Loss [200, 200](epoch, minibatch):  0.13377877533435822\n",
            "Loss [200, 300](epoch, minibatch):  0.1409094792790711\n",
            "Loss [200, 400](epoch, minibatch):  0.1289720808342099\n",
            "Loss [200, 500](epoch, minibatch):  0.13966325026005508\n",
            "Loss [200, 600](epoch, minibatch):  0.12173216627910734\n",
            "Accuracy test images:  83.76 %\n",
            "Training Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "NE9G-DvdpFeV",
        "outputId": "cc8eee64-f517-4228-9594-35f032e73c26"
      },
      "source": [
        "import seaborn as sns\n",
        "num_epochs = 200\n",
        "plt.figure(1)\n",
        "plt.figure(figsize=(15,5))\n",
        "sns.set_style(style=\"darkgrid\")\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.lineplot(x=range(1,num_epochs+1), y=total_train_loss, label=\"Train Loss\")\n",
        "sns.lineplot(x=range(1,num_epochs+1), y=total_val_loss, label=\"Val Loss\")\n",
        "plt.title(\"Loss\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.lineplot(x=range(1,num_epochs+1), y=score_list, label=\"Test Score\")\n",
        "plt.title(\"Score\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"score\")\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}